warning: in the working copy of 'projet.ipynb', LF will be replaced by CRLF the next time Git touches it
diff --git a/projet.ipynb b/projet.ipynb
index 29555b9..57e22ef 100644
--- a/projet.ipynb
+++ b/projet.ipynb
@@ -23,15 +23,20 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.457425Z",
+     "start_time": "2025-12-11T09:33:04.900982Z"
+    }
+   },
    "source": [
     "import numpy as np\n",
     "import pandas as pd\n",
     "import gymnasium as gym\n",
     "import gym_trading_env"
-   ]
+   ],
+   "outputs": [],
+   "execution_count": 1
   },
   {
    "cell_type": "markdown",
@@ -46,11 +51,42 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
-   "metadata": {},
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.499527Z",
+     "start_time": "2025-12-11T09:33:05.465013Z"
+    }
+   },
+   "source": [
+    "def preprocess(df):\n",
+    "    df = df.sort_index()\n",
+    "    df = df.dropna()\n",
+    "    df = df.drop_duplicates()\n",
+    "    return df\n",
+    "\n",
+    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
+    "df.head(5)"
+   ],
    "outputs": [
     {
      "data": {
+      "text/plain": [
+       "                       open    high     low   close       volume  \\\n",
+       "date_open                                                          \n",
+       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
+       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
+       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
+       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
+       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
+       "\n",
+       "                             date_close  \n",
+       "date_open                                \n",
+       "2020-08-18 07:00:00 2020-08-18 08:00:00  \n",
+       "2020-08-18 08:00:00 2020-08-18 09:00:00  \n",
+       "2020-08-18 09:00:00 2020-08-18 10:00:00  \n",
+       "2020-08-18 10:00:00 2020-08-18 11:00:00  \n",
+       "2020-08-18 11:00:00 2020-08-18 12:00:00  "
+      ],
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
@@ -136,23 +172,6 @@
        "  </tbody>\n",
        "</table>\n",
        "</div>"
-      ],
-      "text/plain": [
-       "                       open    high     low   close       volume  \\\n",
-       "date_open                                                          \n",
-       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
-       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
-       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
-       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
-       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
-       "\n",
-       "                             date_close  \n",
-       "date_open                                \n",
-       "2020-08-18 07:00:00 2020-08-18 08:00:00  \n",
-       "2020-08-18 08:00:00 2020-08-18 09:00:00  \n",
-       "2020-08-18 09:00:00 2020-08-18 10:00:00  \n",
-       "2020-08-18 10:00:00 2020-08-18 11:00:00  \n",
-       "2020-08-18 11:00:00 2020-08-18 12:00:00  "
       ]
      },
      "execution_count": 2,
@@ -160,16 +179,7 @@
      "output_type": "execute_result"
     }
    ],
-   "source": [
-    "def preprocess(df):\n",
-    "    df = df.sort_index()\n",
-    "    df = df.dropna()\n",
-    "    df = df.drop_duplicates()\n",
-    "    return df\n",
-    "\n",
-    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
-    "df.head(5)"
-   ]
+   "execution_count": 2
   },
   {
    "cell_type": "markdown",
@@ -185,9 +195,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.543264Z",
+     "start_time": "2025-12-11T09:33:05.508123Z"
+    }
+   },
    "source": [
     "def preprocess(df):\n",
     "    df = df.sort_index()\n",
@@ -200,7 +213,127 @@
     "\n",
     "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
     "df.head(5)"
-   ]
+   ],
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "                       open    high     low   close       volume  \\\n",
+       "date_open                                                          \n",
+       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
+       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
+       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
+       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
+       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
+       "\n",
+       "                             date_close  feature_close  \n",
+       "date_open                                               \n",
+       "2020-08-18 07:00:00 2020-08-18 08:00:00      -1.891634  \n",
+       "2020-08-18 08:00:00 2020-08-18 09:00:00      -1.891128  \n",
+       "2020-08-18 09:00:00 2020-08-18 10:00:00      -1.892594  \n",
+       "2020-08-18 10:00:00 2020-08-18 11:00:00      -1.890016  \n",
+       "2020-08-18 11:00:00 2020-08-18 12:00:00      -1.894514  "
+      ],
+      "text/html": [
+       "<div>\n",
+       "<style scoped>\n",
+       "    .dataframe tbody tr th:only-of-type {\n",
+       "        vertical-align: middle;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe tbody tr th {\n",
+       "        vertical-align: top;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe thead th {\n",
+       "        text-align: right;\n",
+       "    }\n",
+       "</style>\n",
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: right;\">\n",
+       "      <th></th>\n",
+       "      <th>open</th>\n",
+       "      <th>high</th>\n",
+       "      <th>low</th>\n",
+       "      <th>close</th>\n",
+       "      <th>volume</th>\n",
+       "      <th>date_close</th>\n",
+       "      <th>feature_close</th>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>date_open</th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <th>2020-08-18 07:00:00</th>\n",
+       "      <td>430.00</td>\n",
+       "      <td>435.00</td>\n",
+       "      <td>410.00</td>\n",
+       "      <td>430.30</td>\n",
+       "      <td>487.154463</td>\n",
+       "      <td>2020-08-18 08:00:00</td>\n",
+       "      <td>-1.891634</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2020-08-18 08:00:00</th>\n",
+       "      <td>430.27</td>\n",
+       "      <td>431.79</td>\n",
+       "      <td>430.27</td>\n",
+       "      <td>430.80</td>\n",
+       "      <td>454.176153</td>\n",
+       "      <td>2020-08-18 09:00:00</td>\n",
+       "      <td>-1.891128</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2020-08-18 09:00:00</th>\n",
+       "      <td>430.86</td>\n",
+       "      <td>431.13</td>\n",
+       "      <td>428.71</td>\n",
+       "      <td>429.35</td>\n",
+       "      <td>1183.710884</td>\n",
+       "      <td>2020-08-18 10:00:00</td>\n",
+       "      <td>-1.892594</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2020-08-18 10:00:00</th>\n",
+       "      <td>429.75</td>\n",
+       "      <td>432.69</td>\n",
+       "      <td>428.59</td>\n",
+       "      <td>431.90</td>\n",
+       "      <td>1686.183227</td>\n",
+       "      <td>2020-08-18 11:00:00</td>\n",
+       "      <td>-1.890016</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2020-08-18 11:00:00</th>\n",
+       "      <td>432.09</td>\n",
+       "      <td>432.89</td>\n",
+       "      <td>426.99</td>\n",
+       "      <td>427.45</td>\n",
+       "      <td>1980.692724</td>\n",
+       "      <td>2020-08-18 12:00:00</td>\n",
+       "      <td>-1.894514</td>\n",
+       "    </tr>\n",
+       "  </tbody>\n",
+       "</table>\n",
+       "</div>"
+      ]
+     },
+     "execution_count": 3,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "execution_count": 3
   },
   {
    "cell_type": "markdown",
@@ -234,18 +367,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "[-2.023873   0.88       0.8800949]\n",
-      "{'idx': 1, 'step': 1, 'date': np.datetime64('2023-11-21T15:30:00.000000000'), 'position_index': None, 'position': 0.88, 'real_position': np.float64(0.8800948613860823), 'data_date_close': Timestamp('2023-11-21 16:30:00'), 'data_volume': 257387382, 'data_close': 4531.02978515625, 'data_open': 4527.009765625, 'data_low': 4525.509765625, 'data_high': 4533.509765625, 'portfolio_valuation': np.float64(1000.0163489547764), 'portfolio_distribution_asset': np.float64(0.1942404468186077), 'portfolio_distribution_fiat': np.float64(119.9070989376064), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(1.634882113371942e-05)}\n"
-     ]
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.622272Z",
+     "start_time": "2025-12-11T09:33:05.552640Z"
     }
-   ],
+   },
    "source": [
     "env = gym.make(\n",
     "    \"MultiDatasetTradingEnv\",\n",
@@ -261,7 +388,18 @@
     "obs, reward, terminated, truncated, info = env.step(0.88)\n",
     "print(obs)\n",
     "print(info)"
-   ]
+   ],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[-1.1176176   0.88        0.86199826]\n",
+      "{'idx': 1, 'step': 1, 'date': np.datetime64('2021-01-29T13:00:00.000000000'), 'position_index': None, 'position': 0.88, 'real_position': np.float64(0.8619982420158219), 'data_volume': 47022463.7, 'data_open': 0.05181, 'data_date_close': Timestamp('2021-01-29 14:00:00'), 'data_high': 0.05699, 'data_close': 0.04413, 'data_low': 0.042, 'portfolio_valuation': np.float64(868.8994655314681), 'portfolio_distribution_asset': np.float64(16972.35014223006), 'portfolio_distribution_fiat': np.float64(119.90965375485541), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(-0.14052785024653625)}\n"
+     ]
+    }
+   ],
+   "execution_count": 4
   },
   {
    "cell_type": "markdown",
@@ -278,9 +416,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.654986Z",
+     "start_time": "2025-12-11T09:33:05.630508Z"
+    }
+   },
    "source": [
     "env = gym.make(\n",
     "    \"MultiDatasetTradingEnv\",\n",
@@ -291,7 +432,9 @@
     "    trading_fees=0.1/100,\n",
     "    borrow_interest_rate=0.02/100/24,\n",
     ")"
-   ]
+   ],
+   "outputs": [],
+   "execution_count": 5
   },
   {
    "cell_type": "markdown",
@@ -318,18 +461,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "[-1.3615264  0.25       0.2507494]\n",
-      "{'idx': 1, 'step': 1, 'date': np.datetime64('2023-11-21T14:00:00.000000000'), 'position_index': 2, 'position': 0.25, 'real_position': np.float64(0.250749400488757), 'data_date_close': Timestamp('2023-11-21 15:00:00'), 'data_volume': 36358, 'data_close': 2007.5999755859375, 'data_open': 1999.699951171875, 'data_low': 1999.300048828125, 'data_high': 2009.699951171875, 'portfolio_valuation': np.float64(1000.5117065718047), 'portfolio_distribution_asset': np.float64(0.12496399365199337), 'portfolio_distribution_fiat': np.float64(749.6339959669415), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(0.0005115756946421896)}\n"
-     ]
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.681956Z",
+     "start_time": "2025-12-11T09:33:05.662301Z"
     }
-   ],
+   },
    "source": [
     "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
     "\n",
@@ -342,7 +479,18 @@
     "obs, reward, terminated, truncated, info = wrapper.step(2)\n",
     "print(obs)\n",
     "print(info)"
-   ]
+   ],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[-0.16626613  0.25        0.25014377]\n",
+      "{'idx': 1, 'step': 1, 'date': np.datetime64('2023-11-21T14:00:00.000000000'), 'position_index': 2, 'position': 0.25, 'real_position': np.float64(0.2501437786412375), 'data_volume': 0, 'data_open': 1.0949305295944214, 'data_date_close': Timestamp('2023-11-21 15:00:00'), 'data_high': 1.0961307287216187, 'data_close': 1.0955302715301514, 'data_low': 1.0948106050491333, 'portfolio_valuation': np.float64(1000.0093399728391), 'portfolio_distribution_asset': np.float64(228.33336647827292), 'portfolio_distribution_fiat': np.float64(749.8632249955033), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(9.339929221864947e-06)}\n"
+     ]
+    }
+   ],
+   "execution_count": 6
   },
   {
    "cell_type": "markdown",
@@ -364,9 +512,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:05.745429Z",
+     "start_time": "2025-12-11T09:33:05.688496Z"
+    }
+   },
    "source": [
     "def reward_function(history):\n",
     "    return history['portfolio_valuation', -1]\n",
@@ -381,7 +532,9 @@
     "    # On spécifie la fonction de récompense\n",
     "    reward_function=reward_function,\n",
     ")"
-   ]
+   ],
+   "outputs": [],
+   "execution_count": 7
   },
   {
    "cell_type": "markdown",
@@ -404,22 +557,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Episode n˚1 -- Jeu de donnée yfinance-CAC40-1h.pkl\n",
-      "Market Return : 10.54%   |   Portfolio Return : -99.21%   |   \n",
-      "Épisode terminé\n",
-      "Episode n˚2 -- Jeu de donnée binance-BTCUSD-1h.pkl\n",
-      "Market Return : 677.81%   |   Portfolio Return : -100.00%   |   \n",
-      "Épisode terminé\n"
-     ]
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:06.549346Z",
+     "start_time": "2025-12-11T09:33:05.752216Z"
     }
-   ],
+   },
    "source": [
     "nb_episodes = 2\n",
     "for episode in range(1, nb_episodes + 1):\n",
@@ -436,7 +579,22 @@
     "        print('Argent perdu')\n",
     "    elif truncated:\n",
     "        print('Épisode terminé')\n"
-   ]
+   ],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Episode n˚1 -- Jeu de donnée yfinance-EURUSD-1h.pkl\n",
+      "Market Return :  5.27%   |   Portfolio Return : -100.00%   |   \n",
+      "Épisode terminé\n",
+      "Episode n˚2 -- Jeu de donnée yfinance-AAPL-1h.pkl\n",
+      "Market Return : 39.94%   |   Portfolio Return : -96.92%   |   \n",
+      "Épisode terminé\n"
+     ]
+    }
+   ],
+   "execution_count": 8
   },
   {
    "cell_type": "markdown",
@@ -452,17 +610,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Market Return : 27.70%   |   Portfolio Return : -98.62%   |   Portfolio Valuation : 13.78   |   \n"
-     ]
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:06.773682Z",
+     "start_time": "2025-12-11T09:33:06.555285Z"
     }
-   ],
+   },
    "source": [
     "def metric_portfolio_valuation(history):\n",
     "    return round(history['portfolio_valuation', -1], 2)\n",
@@ -476,7 +629,17 @@
     "    action = env.action_space.sample()\n",
     "    obs, reward, terminated, truncated, _ = env.step(action)\n",
     "    done = terminated or truncated"
-   ]
+   ],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Market Return : 10.54%   |   Portfolio Return : -98.67%   |   Portfolio Valuation : 13.33   |   \n"
+     ]
+    }
+   ],
+   "execution_count": 9
   },
   {
    "cell_type": "markdown",
@@ -517,24 +680,29 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
-   "metadata": {},
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:06.784809Z",
+     "start_time": "2025-12-11T09:33:06.780582Z"
+    }
+   },
+   "source": [
+    "portfolio_valuation = env.historical_info['portfolio_valuation', -1]\n",
+    "# Si on avait WandB :\n",
+    "# run.summary['portfolio_valuation'] = portfolio_valuation\n",
+    "# On simule ça par un simple print...\n",
+    "print(portfolio_valuation)"
+   ],
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "13.776557403283697\n"
+      "13.32516244673074\n"
      ]
     }
    ],
-   "source": [
-    "portfolio_valuation = env.historical_info['portfolio_valuation', -1]\n",
-    "# Si on avait WandB :\n",
-    "# run.summary['portfolio_valuation'] = portfolio_valuation\n",
-    "# On simule ça par un simple print...\n",
-    "print(portfolio_valuation)"
-   ]
+   "execution_count": 10
   },
   {
    "cell_type": "markdown",
@@ -545,24 +713,29 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
-   "metadata": {},
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:06.804983Z",
+     "start_time": "2025-12-11T09:33:06.801548Z"
+    }
+   },
+   "source": [
+    "metrics = env.get_metrics()\n",
+    "print(metrics)\n",
+    "portfolio_valuation = metrics['Portfolio Valuation']\n",
+    "print(portfolio_valuation)"
+   ],
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "{'Market Return': '27.70%', 'Portfolio Return': '-98.62%', 'Portfolio Valuation': np.float64(13.78)}\n",
-      "13.78\n"
+      "{'Market Return': '10.54%', 'Portfolio Return': '-98.67%', 'Portfolio Valuation': np.float64(13.33)}\n",
+      "13.33\n"
      ]
     }
    ],
-   "source": [
-    "metrics = env.get_metrics()\n",
-    "print(metrics)\n",
-    "portfolio_valuation = metrics['Portfolio Valuation']\n",
-    "print(portfolio_valuation)"
-   ]
+   "execution_count": 11
   },
   {
    "cell_type": "markdown",
@@ -582,6 +755,665 @@
     "\n",
     "Vous pouvez vous inspirer de travaux existants trouvés sur l'Internet à condition de **citer votre source**. Utiliser le travail de quelqu'un d'autre sans le citer sera considéré comme du plagiat."
    ]
+  },
+  {
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:06.828323Z",
+     "start_time": "2025-12-11T09:33:06.822583Z"
+    }
+   },
+   "cell_type": "code",
+   "source": [
+    "def preprocess_v2(df):\n",
+    "    df = df.sort_index().dropna().drop_duplicates()\n",
+    "\n",
+    "    # --- 1. Log Returns (Rendements Logarithmiques) ---\n",
+    "    df[\"feature_log_returns\"] = np.log(df[\"close\"]).diff()\n",
+    "\n",
+    "    # --- 2. Indicateurs de Volatilité (ATR simplifié) ---\n",
+    "    df['tr1'] = df['high'] - df['low']\n",
+    "    df['tr2'] = np.abs(df['high'] - df['close'].shift(1))\n",
+    "    df['tr3'] = np.abs(df['low'] - df['close'].shift(1))\n",
+    "    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)\n",
+    "    df['feature_atr'] = df['tr'].rolling(window=14).mean() / df[\"close\"]\n",
+    "\n",
+    "    # --- 3. Indicateurs de Tendance (MACD) ---\n",
+    "    ema_fast = df['close'].ewm(span=12, adjust=False).mean()\n",
+    "    ema_slow = df['close'].ewm(span=26, adjust=False).mean()\n",
+    "    df['feature_macd'] = ema_fast - ema_slow\n",
+    "    df['feature_macd_signal'] = df['feature_macd'].ewm(span=9, adjust=False).mean()\n",
+    "\n",
+    "    # --- 4. Indicateurs de Momentum (RSI) ---\n",
+    "    delta = df['close'].diff()\n",
+    "    gain = delta.where(delta > 0, 0)\n",
+    "    loss = -delta.where(delta < 0, 0)\n",
+    "    avg_gain = gain.rolling(window=14).mean()\n",
+    "    avg_loss = loss.rolling(window=14).mean()\n",
+    "    rs = avg_gain / avg_loss\n",
+    "    df['feature_rsi'] = 100 - (100 / (1 + rs)) / 100\n",
+    "\n",
+    "    # --- 5. Nettoyage et Normalisation ---\n",
+    "    df = df.dropna()\n",
+    "    cols_to_normalize = ['feature_log_returns', 'feature_macd', 'feature_macd_signal', 'feature_atr']\n",
+    "    for col in cols_to_normalize:\n",
+    "        if df[col].std() > 0:\n",
+    "            df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
+    "        else:\n",
+    "             df[col] = 0.0\n",
+    "\n",
+    "    return df"
+   ],
+   "outputs": [],
+   "execution_count": 12
+  },
+  {
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T09:33:06.844559Z",
+     "start_time": "2025-12-11T09:33:06.840144Z"
+    }
+   },
+   "cell_type": "code",
+   "source": [
+    "def reward_function_v2(history):\n",
+    "    # Rendement log du portefeuille à l'étape t\n",
+    "    prev_val = history['portfolio_valuation', -2]\n",
+    "    curr_val = history['portfolio_valuation', -1]\n",
+    "\n",
+    "    # Gestion du cas initial\n",
+    "    if prev_val == 0: return 0\n",
+    "\n",
+    "    # Calcul du rendement log\n",
+    "    reward = np.log(curr_val / prev_val)\n",
+    "\n",
+    "    # BONUS : Pénalité de risque (Sharpe Ratio simplifié)\n",
+    "    # Si vous voulez un agent prudent, vous pouvez soustraire une fraction de la volatilité récente\n",
+    "    return reward"
+   ],
+   "outputs": [],
+   "execution_count": 13
+  },
+  {
+   "metadata": {},
+   "cell_type": "markdown",
+   "source": "## Chargement et Configuration"
+  },
+  {
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T10:17:03.313550Z",
+     "start_time": "2025-12-11T10:17:03.308153Z"
+    }
+   },
+   "cell_type": "code",
+   "source": [
+    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
+    "import numpy as np\n",
+    "import pandas as pd\n",
+    "\n",
+    "class CustomTradingCallback(BaseCallback):\n",
+    "    \"\"\"\n",
+    "    Callback pour enregistrer les métriques financières finales dans WandB\n",
+    "    à la fin de chaque épisode.\n",
+    "    \"\"\"\n",
+    "    def __init__(self, verbose: int = 0):\n",
+    "        super().__init__(verbose)\n",
+    "        self.episode_num = 0\n",
+    "\n",
+    "    def _on_step(self) -> bool:\n",
+    "        # Vérifie si l'épisode est terminé\n",
+    "        if self.locals['dones'][0]:\n",
+    "            self.episode_num += 1\n",
+    "\n",
+    "            raw_env = self.training_env.envs[0].unwrapped\n",
+    "            metrics = raw_env.get_metrics()\n",
+    "\n",
+    "            # 1. Accéder à l'environnement non-vectorisé\n",
+    "            # Le VecEnv est un wrapper, on doit aller chercher l'env \"nu\"\n",
+    "            raw_env = self.training_env.envs[0].unwrapped\n",
+    "\n",
+    "            # 2. Calculer les métriques\n",
+    "            # Note: gym-trading-env calcule déjà les métriques finales\n",
+    "            metrics = raw_env.get_metrics()\n",
+    "\n",
+    "            # --- Journalisation dans WandB ---\n",
+    "\n",
+    "            # A. Le critère d'évaluation final (Portfolio Valuation)\n",
+    "            final_val = metrics.get('Portfolio Valuation')\n",
+    "\n",
+    "            # B. Performance vs. Marché (pour le contexte)\n",
+    "            market_return_str = metrics.get('Market Return', '0.00%').strip()\n",
+    "            market_return = float(market_return_str.strip('%')) / 100\n",
+    "\n",
+    "            portfolio_return_str = metrics.get('Portfolio Return', '0.00%').strip()\n",
+    "            portfolio_return = float(portfolio_return_str.strip('%')) / 100\n",
+    "\n",
+    "\n",
+    "            if self.logger is not None:\n",
+    "                # Enregistrer les métriques spécifiques\n",
+    "                self.logger.record(\"episode/final_portfolio_valuation\", final_val)\n",
+    "                self.logger.record(\"episode/return_vs_market_pct\", (portfolio_return - market_return) * 100)\n",
+    "                self.logger.record(\"episode/total_portfolio_return_pct\", portfolio_return * 100)\n",
+    "                self.logger.record(\"episode/market_return_pct\", market_return * 100)\n",
+    "                # CORRECTION ICI : Utiliser raw_env.step au lieu de raw_env.steps\n",
+    "                self.logger.record(\"episode/steps\", raw_env.step)\n",
+    "\n",
+    "                # S'assurer que le log est écrit immédiatement\n",
+    "                self.logger.dump(step=self.num_timesteps)\n",
+    "\n",
+    "        return True"
+   ],
+   "outputs": [],
+   "execution_count": 21
+  },
+  {
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T10:12:31.668428Z",
+     "start_time": "2025-12-11T10:09:43.674270Z"
+    }
+   },
+   "cell_type": "code",
+   "source": [
+    "import gymnasium as gym\n",
+    "import gym_trading_env\n",
+    "from sb3_contrib import RecurrentPPO\n",
+    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
+    "\n",
+    "# --- NOUVELLES IMPORTATIONS ---\n",
+    "import wandb\n",
+    "from wandb.integration.sb3 import WandbCallback\n",
+    "\n",
+    "# --- HYPERPARAMÈTRES (pour le suivi WandB) ---\n",
+    "config = {\n",
+    "    \"policy_type\": \"MlpLstmPolicy\",\n",
+    "    \"total_timesteps\": 100_000,\n",
+    "    \"env_id\": \"MultiDatasetTradingEnv\",\n",
+    "    \"learning_rate\": 3e-4,\n",
+    "    \"n_steps\": 2048,\n",
+    "    \"batch_size\": 128,\n",
+    "    \"ent_coef\": 0.01,\n",
+    "    # Ajoutez ici tous les paramètres de l'environnement (frais, capital, etc.)\n",
+    "}\n",
+    "\n",
+    "# --- 1. INITIALISATION DE WANDB ---\n",
+    "run = wandb.init(\n",
+    "    project=\"RL-Trading-Project\", # Nom de votre projet\n",
+    "    entity=\"arthur-collignon-cpe-lyon\", # Remplacez par votre nom d'utilisateur WandB\n",
+    "    config=config,\n",
+    "    sync_tensorboard=True, # Synchroniser TensorBoard (si vous l'utilisez encore)\n",
+    "    monitor_gym=True,\n",
+    "    save_code=True,\n",
+    ")\n",
+    "\n",
+    "# --- 2. CRÉATION DE L'ENVIRONNEMENT ET DU MODÈLE (Comme avant) ---\n",
+    "\n",
+    "# ... (Vos fonctions preprocess/reward_function ici) ...\n",
+    "\n",
+    "env = gym.make(\n",
+    "    \"MultiDatasetTradingEnv\",\n",
+    "    dataset_dir=\"data/*.pkl\",\n",
+    "    preprocess=preprocess,\n",
+    "    reward_function=reward_function,\n",
+    "    position_range=(-1, 1),\n",
+    "    portfolio_initial_value=1_000,\n",
+    "    trading_fees=0.1/100,\n",
+    "    borrow_interest_rate=0.02/100/24,\n",
+    ")\n",
+    "\n",
+    "env = DummyVecEnv([lambda: env])\n",
+    "\n",
+    "model = RecurrentPPO(\n",
+    "    config[\"policy_type\"], # Utiliser le dictionnaire de config\n",
+    "    env,\n",
+    "    verbose=0, # Mettre à 0 pour éviter les logs console en faveur de WandB\n",
+    "    learning_rate=config[\"learning_rate\"],\n",
+    "    n_steps=config[\"n_steps\"],\n",
+    "    batch_size=config[\"batch_size\"],\n",
+    "    ent_coef=config[\"ent_coef\"],\n",
+    "    tensorboard_log=f\"runs/{run.id}\", # Pointer le log TensorBoard vers le dossier de WandB\n",
+    ")\n",
+    "\n",
+    "# --- DÉFINITION DE LA LISTE DE CALLBACKS ---\n",
+    "callback = CallbackList([\n",
+    "    # Callback SB3 WandB: gère les logs d'entraînement (reward, loss, entropie)\n",
+    "    WandbCallback(\n",
+    "        model_save_path=f\"models/{run.id}\",\n",
+    "        verbose=0,\n",
+    "        model_save_freq=10000,\n",
+    "    ),\n",
+    "    # Callback Personnalisé: gère les logs financiers (portfolio_valuation, returns)\n",
+    "    CustomTradingCallback(verbose=0),\n",
+    "])\n",
+    "\n",
+    "\n",
+    "# --- ENTRAÎNEMENT AVEC LA LISTE DE CALLBACKS ---\n",
+    "try:\n",
+    "    print(\"Début de l'entraînement avec WandB...\")\n",
+    "    model.learn(\n",
+    "        total_timesteps=config[\"total_timesteps\"],\n",
+    "        callback=callback, # Passe la liste des deux Callbacks\n",
+    "    )\n",
+    "finally:\n",
+    "    run.finish()"
+   ],
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "Finishing previous runs because reinit is set to 'default'."
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": []
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": "b4532126fbd16d5f7e7a05234838e1d9"
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       " View run <strong style=\"color:#cdcd00\">tough-eon-2</strong> at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/5cioxr0u' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/5cioxr0u</a><br> View project at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a><br>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "Find logs at: <code>.\\wandb\\run-20251211_110846-5cioxr0u\\logs</code>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": []
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": "f5fc0890ad0cf883c694923bc2cdf78f"
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "Tracking run with wandb version 0.23.1"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "Run data is saved locally in <code>C:\\Users\\arthu\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\wandb\\run-20251211_110944-40tpnazz</code>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "Syncing run <strong><a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/40tpnazz' target=\"_blank\">iconic-resonance-3</a></strong> to <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       " View project at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       " View run at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/40tpnazz' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/40tpnazz</a>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Début de l'entraînement avec WandB...\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n",
+      "wandb: WARNING Linked 1 file into the W&B run directory (hardlinks); call wandb.save again to sync new files.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Market Return : 677.81%   |   Portfolio Return : -100.00%   |   \n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": []
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": "e9510ffecea2f27f7631d2f453afe21f"
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇████</td></tr><tr><td>time/fps</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/approx_kl</td><td>▁▁▁▁▁▂▁▁▄█▆▅▇█▆▆▄▇▆█▆</td></tr><tr><td>train/clip_fraction</td><td>▁▁▁▁▁▁▁▁▁▆▃▄▅▆▅▅▃█▇▅█</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▂▂▁▂▃▄▄▃▂▂▂▃▃▃▄▃▆▇███</td></tr><tr><td>train/explained_variance</td><td>▆▆▆▆▆▆▆▇▆▆▅▆▇▅▇▆▆▆▄█▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/policy_gradient_loss</td><td>████████▇▄▅▄▃▁▃▃▅▂▃▄▂</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>45056</td></tr><tr><td>time/fps</td><td>288</td></tr><tr><td>train/approx_kl</td><td>0.00487</td></tr><tr><td>train/clip_fraction</td><td>0.06401</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-1.3789</td></tr><tr><td>train/explained_variance</td><td>-0.00032</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>-0.02405</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.0047</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       " View run <strong style=\"color:#cdcd00\">iconic-resonance-3</strong> at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/40tpnazz' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/40tpnazz</a><br> View project at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a><br>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ],
+      "text/html": [
+       "Find logs at: <code>.\\wandb\\run-20251211_110944-40tpnazz\\logs</code>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data",
+     "jetTransient": {
+      "display_id": null
+     }
+    },
+    {
+     "ename": "AttributeError",
+     "evalue": "'MultiDatasetTradingEnv' object has no attribute 'steps'",
+     "output_type": "error",
+     "traceback": [
+      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
+      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
+      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 76\u001B[39m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     75\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mDébut de l\u001B[39m\u001B[33m'\u001B[39m\u001B[33mentraînement avec WandB...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m     \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtotal_timesteps\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Passe la liste des deux Callbacks\u001B[39;49;00m\n\u001B[32m     79\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     81\u001B[39m     run.finish()\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:450\u001B[39m, in \u001B[36mRecurrentPPO.learn\u001B[39m\u001B[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[39m\n\u001B[32m    441\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlearn\u001B[39m(\n\u001B[32m    442\u001B[39m     \u001B[38;5;28mself\u001B[39m: SelfRecurrentPPO,\n\u001B[32m    443\u001B[39m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    448\u001B[39m     progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    449\u001B[39m ) -> SelfRecurrentPPO:\n\u001B[32m--> \u001B[39m\u001B[32m450\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    452\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:324\u001B[39m, in \u001B[36mOnPolicyAlgorithm.learn\u001B[39m\u001B[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[39m\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.env \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    323\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m.num_timesteps < total_timesteps:\n\u001B[32m--> \u001B[39m\u001B[32m324\u001B[39m     continue_training = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrollout_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_rollout_steps\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    326\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m continue_training:\n\u001B[32m    327\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:258\u001B[39m, in \u001B[36mRecurrentPPO.collect_rollouts\u001B[39m\u001B[34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001B[39m\n\u001B[32m    256\u001B[39m \u001B[38;5;66;03m# Give access to local variables\u001B[39;00m\n\u001B[32m    257\u001B[39m callback.update_locals(\u001B[38;5;28mlocals\u001B[39m())\n\u001B[32m--> \u001B[39m\u001B[32m258\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m.\u001B[49m\u001B[43mon_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    261\u001B[39m \u001B[38;5;28mself\u001B[39m._update_info_buffer(infos, dones)\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001B[39m, in \u001B[36mBaseCallback.on_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28mself\u001B[39m.n_calls += \u001B[32m1\u001B[39m\n\u001B[32m    112\u001B[39m \u001B[38;5;28mself\u001B[39m.num_timesteps = \u001B[38;5;28mself\u001B[39m.model.num_timesteps\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_on_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:223\u001B[39m, in \u001B[36mCallbackList._on_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    220\u001B[39m continue_training = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    221\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callbacks:\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# Return False (stop training) if at least one callback returns False\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m223\u001B[39m     continue_training = \u001B[43mcallback\u001B[49m\u001B[43m.\u001B[49m\u001B[43mon_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m continue_training\n\u001B[32m    224\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m continue_training\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001B[39m, in \u001B[36mBaseCallback.on_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28mself\u001B[39m.n_calls += \u001B[32m1\u001B[39m\n\u001B[32m    112\u001B[39m \u001B[38;5;28mself\u001B[39m.num_timesteps = \u001B[38;5;28mself\u001B[39m.model.num_timesteps\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_on_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 46\u001B[39m, in \u001B[36mCustomTradingCallback._on_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     44\u001B[39m \u001B[38;5;28mself\u001B[39m.logger.record(\u001B[33m\"\u001B[39m\u001B[33mepisode/total_portfolio_return_pct\u001B[39m\u001B[33m\"\u001B[39m, portfolio_return * \u001B[32m100\u001B[39m)\n\u001B[32m     45\u001B[39m \u001B[38;5;28mself\u001B[39m.logger.record(\u001B[33m\"\u001B[39m\u001B[33mepisode/market_return_pct\u001B[39m\u001B[33m\"\u001B[39m, market_return * \u001B[32m100\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[38;5;28mself\u001B[39m.logger.record(\u001B[33m\"\u001B[39m\u001B[33mepisode/steps\u001B[39m\u001B[33m\"\u001B[39m, \u001B[43mraw_env\u001B[49m\u001B[43m.\u001B[49m\u001B[43msteps\u001B[49m)\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# S'assurer que le log est écrit immédiatement\u001B[39;00m\n\u001B[32m     49\u001B[39m \u001B[38;5;28mself\u001B[39m.logger.dump(step=\u001B[38;5;28mself\u001B[39m.num_timesteps)\n",
+      "\u001B[31mAttributeError\u001B[39m: 'MultiDatasetTradingEnv' object has no attribute 'steps'"
+     ]
+    }
+   ],
+   "execution_count": 20
+  },
+  {
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2025-12-11T10:03:27.663523Z",
+     "start_time": "2025-12-11T10:03:27.291321Z"
+    }
+   },
+   "cell_type": "code",
+   "source": [
+    "import gymnasium as gym\n",
+    "import gym_trading_env\n",
+    "from sb3_contrib import RecurrentPPO\n",
+    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
+    "import numpy as np\n",
+    "import pandas as pd\n",
+    "import matplotlib.pyplot as plt\n",
+    "\n",
+    "# --- 1. Récupération des fonctions (Doivent être identiques à l'entraînement) ---\n",
+    "# Copiez-collez ici votre fonction preprocess() améliorée de l'étape précédente\n",
+    "# et votre reward_function (bien que pour le test, la reward ne serve à rien,\n",
+    "# l'env en a besoin pour s'initialiser).\n",
+    "\n",
+    "# --- 2. Chargement de l'environnement de Test ---\n",
+    "# Idéalement, pointez vers un fichier .pkl que l'agent n'a JAMAIS vu (ex: 2024.pkl)\n",
+    "# Si vous n'avez pas de données séparées, utilisez le même dossier mais gardez en tête\n",
+    "# que le résultat sera biaisé (overfitting).\n",
+    "env_test = gym.make(\n",
+    "    \"MultiDatasetTradingEnv\",\n",
+    "    dataset_dir=\"data/*.pkl\",\n",
+    "    preprocess=preprocess_v2,\n",
+    "    reward_function=reward_function_v2,\n",
+    "    position_range=(-1, 1),\n",
+    "    portfolio_initial_value=1_000,\n",
+    "    trading_fees=0.1/100,\n",
+    "    borrow_interest_rate=0.02/100/24,\n",
+    "    # CETTE LIGNE DOIT ÊTRE SUPPRIMÉE :\n",
+    "    # window_size=1\n",
+    ")\n",
+    "\n",
+    "# On wrap l'environnement comme pour l'entraînement\n",
+    "env_test = DummyVecEnv([lambda: env_test])\n",
+    "\n",
+    "# --- 3. Chargement de l'Agent ---\n",
+    "# On charge le modèle sauvegardé\n",
+    "model = RecurrentPPO.load(\"mon_agent_trading\")\n",
+    "\n",
+    "print(\"Modèle chargé avec succès. Début du backtest...\")"
+   ],
+   "outputs": [
+    {
+     "ename": "FileNotFoundError",
+     "evalue": "[Errno 2] No such file or directory: 'mon_agent_trading.zip'",
+     "output_type": "error",
+     "traceback": [
+      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
+      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
+      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     32\u001B[39m env_test = DummyVecEnv([\u001B[38;5;28;01mlambda\u001B[39;00m: env_test])\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m# --- 3. Chargement de l'Agent ---\u001B[39;00m\n\u001B[32m     35\u001B[39m \u001B[38;5;66;03m# On charge le modèle sauvegardé\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m model = \u001B[43mRecurrentPPO\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmon_agent_trading\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mModèle chargé avec succès. Début du backtest...\u001B[39m\u001B[33m\"\u001B[39m)\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:681\u001B[39m, in \u001B[36mBaseAlgorithm.load\u001B[39m\u001B[34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001B[39m\n\u001B[32m    678\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m== CURRENT SYSTEM INFO ==\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    679\u001B[39m     get_system_info()\n\u001B[32m--> \u001B[39m\u001B[32m681\u001B[39m data, params, pytorch_variables = \u001B[43mload_from_zip_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    682\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    683\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    684\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    685\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprint_system_info\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprint_system_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    686\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    688\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mNo data found in the saved file\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    689\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mNo params found in the saved file\u001B[39m\u001B[33m\"\u001B[39m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:403\u001B[39m, in \u001B[36mload_from_zip_file\u001B[39m\u001B[34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001B[39m\n\u001B[32m    376\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_from_zip_file\u001B[39m(\n\u001B[32m    377\u001B[39m     load_path: Union[\u001B[38;5;28mstr\u001B[39m, pathlib.Path, io.BufferedIOBase],\n\u001B[32m    378\u001B[39m     load_data: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    382\u001B[39m     print_system_info: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    383\u001B[39m ) -> \u001B[38;5;28mtuple\u001B[39m[Optional[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001B[32m    384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    385\u001B[39m \u001B[33;03m    Load model data from a .zip archive\u001B[39;00m\n\u001B[32m    386\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    401\u001B[39m \u001B[33;03m        and dict of pytorch variables\u001B[39;00m\n\u001B[32m    402\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m     file = \u001B[43mopen_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mload_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuffix\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mzip\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    405\u001B[39m     \u001B[38;5;66;03m# set device to cpu if cuda is not available\u001B[39;00m\n\u001B[32m    406\u001B[39m     device = get_device(device=device)\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\functools.py:934\u001B[39m, in \u001B[36msingledispatch.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kw)\u001B[39m\n\u001B[32m    931\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[32m    932\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m requires at least \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    933\u001B[39m                     \u001B[33m'\u001B[39m\u001B[33m1 positional argument\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m934\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:240\u001B[39m, in \u001B[36mopen_path_str\u001B[39m\u001B[34m(path, mode, verbose, suffix)\u001B[39m\n\u001B[32m    225\u001B[39m \u001B[38;5;129m@open_path\u001B[39m.register(\u001B[38;5;28mstr\u001B[39m)\n\u001B[32m    226\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mopen_path_str\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m, mode: \u001B[38;5;28mstr\u001B[39m, verbose: \u001B[38;5;28mint\u001B[39m = \u001B[32m0\u001B[39m, suffix: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m) -> io.BufferedIOBase:\n\u001B[32m    227\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    228\u001B[39m \u001B[33;03m    Open a path given by a string. If writing to the path, the function ensures\u001B[39;00m\n\u001B[32m    229\u001B[39m \u001B[33;03m    that the path exists.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    238\u001B[39m \u001B[33;03m    :return:\u001B[39;00m\n\u001B[32m    239\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopen_path_pathlib\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpathlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuffix\u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:291\u001B[39m, in \u001B[36mopen_path_pathlib\u001B[39m\u001B[34m(path, mode, verbose, suffix)\u001B[39m\n\u001B[32m    285\u001B[39m         path.parent.mkdir(exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m, parents=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    287\u001B[39m \u001B[38;5;66;03m# if opening was successful uses the open_path() function\u001B[39;00m\n\u001B[32m    288\u001B[39m \u001B[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001B[39;00m\n\u001B[32m    289\u001B[39m \u001B[38;5;66;03m#   with corrections\u001B[39;00m\n\u001B[32m    290\u001B[39m \u001B[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m291\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopen_path_pathlib\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuffix\u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:272\u001B[39m, in \u001B[36mopen_path_pathlib\u001B[39m\u001B[34m(path, mode, verbose, suffix)\u001B[39m\n\u001B[32m    270\u001B[39m             path, suffix = newpath, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    271\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m272\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m error\n\u001B[32m    273\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    274\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:264\u001B[39m, in \u001B[36mopen_path_pathlib\u001B[39m\u001B[34m(path, mode, verbose, suffix)\u001B[39m\n\u001B[32m    262\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mode == \u001B[33m\"\u001B[39m\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    263\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m264\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m open_path(\u001B[43mpath\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m, mode, verbose, suffix)\n\u001B[32m    265\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[32m    266\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m suffix \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m suffix != \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m:\n",
+      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_local.py:537\u001B[39m, in \u001B[36mPath.open\u001B[39m\u001B[34m(self, mode, buffering, encoding, errors, newline)\u001B[39m\n\u001B[32m    535\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m    536\u001B[39m     encoding = io.text_encoding(encoding)\n\u001B[32m--> \u001B[39m\u001B[32m537\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffering\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m)\u001B[49m\n",
+      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'mon_agent_trading.zip'"
+     ]
+    }
+   ],
+   "execution_count": 17
+  },
+  {
+   "metadata": {},
+   "cell_type": "markdown",
+   "source": "## Exécution du Backtest (La boucle de prédiction)"
+  },
+  {
+   "metadata": {},
+   "cell_type": "code",
+   "source": [
+    "# Reset de l'environnement\n",
+    "obs = env_test.reset()\n",
+    "\n",
+    "# Pour les LSTM, nous devons gérer les états cachés (cell state / hidden state)\n",
+    "# Initialement, ils sont vides (None) ou zéros\n",
+    "_states = None\n",
+    "\n",
+    "done = False\n",
+    "\n",
+    "while not done:\n",
+    "    # L'agent prédit l'action à prendre\n",
+    "    # deterministic=True est CRUCIAL pour le test : on supprime l'aléatoire de l'exploration\n",
+    "    action, _states = model.predict(obs, state=_states, deterministic=True)\n",
+    "\n",
+    "    # On joue l'action dans l'environnement\n",
+    "    obs, reward, done, info = env_test.step(action)\n",
+    "\n",
+    "    # Note : Dans SB3 avec VecEnv, 'done' est un tableau de booléens.\n",
+    "    # L'environnement se reset automatiquement quand done=True.\n",
+    "    # Pour un backtest unique, on veut sortir de la boucle quand l'épisode finit.\n",
+    "    if done[0]:\n",
+    "        break\n",
+    "\n",
+    "print(\"Backtest terminé.\")"
+   ],
+   "outputs": [],
+   "execution_count": null
+  },
+  {
+   "metadata": {},
+   "cell_type": "markdown",
+   "source": "## Analyse des Résultats et Visualisation"
+  },
+  {
+   "metadata": {},
+   "cell_type": "code",
+   "source": [
+    "# On récupère l'environnement \"nu\" (sans le wrapper VecEnv de SB3)\n",
+    "raw_env = env_test.envs[0].unwrapped\n",
+    "\n",
+    "# Récupération de l'historique complet sous forme de DataFrame\n",
+    "df_results = raw_env.save_for_render(dir=\"render_logs\")\n",
+    "# Cela crée aussi un rendu HTML interactif dans le dossier 'render_logs' !\n",
+    "\n",
+    "# --- Affichage des Métriques Clés ---\n",
+    "metrics = raw_env.get_metrics()\n",
+    "print(\"\\n--- RÉSULTATS DU BACKTEST ---\")\n",
+    "print(f\"Rendement du Marché (Buy & Hold) : {metrics['Market Return']}\")\n",
+    "print(f\"Rendement de l'Agent             : {metrics['Portfolio Return']}\")\n",
+    "print(f\"Valeur Finale du Portefeuille    : {metrics['Portfolio Valuation']:.2f} $\")\n",
+    "print(\"-\" * 30)\n",
+    "\n",
+    "# --- Comparaison Graphique ---\n",
+    "# On va tracer la valeur du portefeuille vs le prix de l'actif (normalisé)\n",
+    "\n",
+    "plt.figure(figsize=(15, 6))\n",
+    "\n",
+    "# 1. Courbe de l'Agent (Valeur du portefeuille)\n",
+    "plt.plot(df_results.index, df_results['portfolio_valuation'], label='Agent AI', color='blue', linewidth=2)\n",
+    "\n",
+    "# 2. Courbe du \"Buy & Hold\" (Si on avait juste acheté au début)\n",
+    "# On normalise le prix de l'actif pour qu'il commence à 1000$ (comme le portefeuille)\n",
+    "initial_price = df_results['data_close'].iloc[0]\n",
+    "initial_portfolio = df_results['portfolio_valuation'].iloc[0]\n",
+    "factor = initial_portfolio / initial_price\n",
+    "plt.plot(df_results.index, df_results['data_close'] * factor, label='Buy & Hold (Marché)', color='gray', linestyle='--', alpha=0.7)\n",
+    "\n",
+    "plt.title(\"Performance : Intelligence Artificielle vs Marché\")\n",
+    "plt.xlabel(\"Temps\")\n",
+    "plt.ylabel(\"Valeur du Portefeuille ($)\")\n",
+    "plt.legend()\n",
+    "plt.grid(True, alpha=0.3)\n",
+    "plt.show()\n",
+    "\n",
+    "# --- Visualisation des Positions ---\n",
+    "# Pour voir QUAND l'agent achète ou vend\n",
+    "plt.figure(figsize=(15, 4))\n",
+    "plt.plot(df_results.index, df_results['position'], label='Position de l\\'Agent', color='orange')\n",
+    "plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
+    "plt.axhline(y=1, color='green', linestyle=':', alpha=0.5, label='100% Long')\n",
+    "plt.axhline(y=-1, color='red', linestyle=':', alpha=0.5, label='100% Short')\n",
+    "plt.title(\"Décisions de l'Agent au cours du temps\")\n",
+    "plt.ylabel(\"Position (-1 = Short, 1 = Long)\")\n",
+    "plt.legend()\n",
+    "plt.show()"
+   ],
+   "outputs": [],
+   "execution_count": null
   }
  ],
  "metadata": {
