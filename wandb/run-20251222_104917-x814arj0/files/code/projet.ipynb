{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL -- Projet \"Trading automatique\"\n",
    "\n",
    "Ce notebook contient du code de base et quelques explications pour vous aider sur ce sujet.\n",
    "\n",
    "Vous êtes libres de réaliser ce projet avec des scripts Python ou des Jupyter Notebooks, à votre convenance.\n",
    "\n",
    "Vous devez télécharger les paquets Python suivants :\n",
    "\n",
    "```sh\n",
    "pip install gymnasium\n",
    "pip install pandas\n",
    "pip install gym-trading-env-continuous\n",
    "```\n",
    "\n",
    "Vous utiliserez l'environnement `gym-trading-env-continuous`, qui est un *fork* de [Gym Trading Env](https://gym-trading-env.readthedocs.io/en/latest/index.html). La différence majeure est expliquée dans ce document ; la documentation originelle reste utilisable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:23.981892Z",
     "start_time": "2025-12-22T09:47:23.086152Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import gym_trading_env"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation des données de simulation\n",
    "\n",
    "Les données sont dans un format binaire (Pickle) que vous pouvez lire avec Pandas. Vous devez vous assurer que les données sont triées par date.\n",
    "\n",
    "Des étapes de prétraitement peuvent aider votre apprentissage, par exemple, supprimer les doublons, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:24.240791Z",
     "start_time": "2025-12-22T09:47:23.993031Z"
    }
   },
   "source": [
    "def preprocess(df):\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
    "df.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       open    high     low   close       volume  \\\n",
       "date_open                                                          \n",
       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
       "\n",
       "                             date_close  \n",
       "date_open                                \n",
       "2020-08-18 07:00:00 2020-08-18 08:00:00  \n",
       "2020-08-18 08:00:00 2020-08-18 09:00:00  \n",
       "2020-08-18 09:00:00 2020-08-18 10:00:00  \n",
       "2020-08-18 10:00:00 2020-08-18 11:00:00  \n",
       "2020-08-18 11:00:00 2020-08-18 12:00:00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_open</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-18 07:00:00</th>\n",
       "      <td>430.00</td>\n",
       "      <td>435.00</td>\n",
       "      <td>410.00</td>\n",
       "      <td>430.30</td>\n",
       "      <td>487.154463</td>\n",
       "      <td>2020-08-18 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 08:00:00</th>\n",
       "      <td>430.27</td>\n",
       "      <td>431.79</td>\n",
       "      <td>430.27</td>\n",
       "      <td>430.80</td>\n",
       "      <td>454.176153</td>\n",
       "      <td>2020-08-18 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 09:00:00</th>\n",
       "      <td>430.86</td>\n",
       "      <td>431.13</td>\n",
       "      <td>428.71</td>\n",
       "      <td>429.35</td>\n",
       "      <td>1183.710884</td>\n",
       "      <td>2020-08-18 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 10:00:00</th>\n",
       "      <td>429.75</td>\n",
       "      <td>432.69</td>\n",
       "      <td>428.59</td>\n",
       "      <td>431.90</td>\n",
       "      <td>1686.183227</td>\n",
       "      <td>2020-08-18 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 11:00:00</th>\n",
       "      <td>432.09</td>\n",
       "      <td>432.89</td>\n",
       "      <td>426.99</td>\n",
       "      <td>427.45</td>\n",
       "      <td>1980.692724</td>\n",
       "      <td>2020-08-18 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de *features*\n",
    "\n",
    "Vous pouvez également rajouter de nouvelles données au DataFrame pour créer de nouvelles *features* que l'agent pourra utiliser.\n",
    "Voir pour cela la [doc](https://gym-trading-env.readthedocs.io/en/latest/features.html).\n",
    "\n",
    "Chaque nouvelle *feature* doit commencer par `feature_` pour être détectée."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:24.459385Z",
     "start_time": "2025-12-22T09:47:24.255880Z"
    }
   },
   "source": [
    "def preprocess(df):\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df['feature_close'] = (df['close'] - df['close'].mean()) / df['close'].std()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
    "df.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       open    high     low   close       volume  \\\n",
       "date_open                                                          \n",
       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
       "\n",
       "                             date_close  feature_close  \n",
       "date_open                                               \n",
       "2020-08-18 07:00:00 2020-08-18 08:00:00      -1.891634  \n",
       "2020-08-18 08:00:00 2020-08-18 09:00:00      -1.891128  \n",
       "2020-08-18 09:00:00 2020-08-18 10:00:00      -1.892594  \n",
       "2020-08-18 10:00:00 2020-08-18 11:00:00      -1.890016  \n",
       "2020-08-18 11:00:00 2020-08-18 12:00:00      -1.894514  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date_close</th>\n",
       "      <th>feature_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_open</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-18 07:00:00</th>\n",
       "      <td>430.00</td>\n",
       "      <td>435.00</td>\n",
       "      <td>410.00</td>\n",
       "      <td>430.30</td>\n",
       "      <td>487.154463</td>\n",
       "      <td>2020-08-18 08:00:00</td>\n",
       "      <td>-1.891634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 08:00:00</th>\n",
       "      <td>430.27</td>\n",
       "      <td>431.79</td>\n",
       "      <td>430.27</td>\n",
       "      <td>430.80</td>\n",
       "      <td>454.176153</td>\n",
       "      <td>2020-08-18 09:00:00</td>\n",
       "      <td>-1.891128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 09:00:00</th>\n",
       "      <td>430.86</td>\n",
       "      <td>431.13</td>\n",
       "      <td>428.71</td>\n",
       "      <td>429.35</td>\n",
       "      <td>1183.710884</td>\n",
       "      <td>2020-08-18 10:00:00</td>\n",
       "      <td>-1.892594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 10:00:00</th>\n",
       "      <td>429.75</td>\n",
       "      <td>432.69</td>\n",
       "      <td>428.59</td>\n",
       "      <td>431.90</td>\n",
       "      <td>1686.183227</td>\n",
       "      <td>2020-08-18 11:00:00</td>\n",
       "      <td>-1.890016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 11:00:00</th>\n",
       "      <td>432.09</td>\n",
       "      <td>432.89</td>\n",
       "      <td>426.99</td>\n",
       "      <td>427.45</td>\n",
       "      <td>1980.692724</td>\n",
       "      <td>2020-08-18 12:00:00</td>\n",
       "      <td>-1.894514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, l'agent ne reçoit comme *features* que sa dernière *position* (voir le paragraphe suivant), ce qui ne sera certainement pas suffisant ! À vous d'ajouter les *features* qui seront pertinentes pour que l'agent apprenne la politique optimale..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctionnement des actions\n",
    "\n",
    "Une action est une **position**, c'est-à-dire un ratio entre la proportion d'*assets* (exemple : ETH) et la proportion de *fiat* (exemple : USD) dans le portefeuille.\n",
    "Ainsi, la position `0.5` consiste à avoir exactement 50% d'ETH et 50% d'USD (en vendant l'un ou l'autre pour arriver à ce ratio). `0.1` consiste à avoir 10% d'ETH et 90% d'USD.\n",
    "\n",
    "Il existe des positions un peu plus complexes :\n",
    "\n",
    "- `< 0` : une position inférieure à 0 va vendre encore plus d'ETH que le portefeuille n'en contient, pour obtenir des USD. Cela nécessite un emprunt, qui sera remboursé avec un intérêt.\n",
    "- `> 1` : une position supérieure à 1 va dépenser encore plus d'USD que le portefeuille n'en contient, pour acheter des ETH. Cela nécessite également un emprunt.\n",
    "\n",
    "Ces positions (qui sont appelées *short* et *margin* en finance) peuvent faire gagner beaucoup à votre agent, mais démultiplient les risques également. Si votre agent fait une bonne affaire, vous pouvez vendre à un prix élevé, racheter quand le prix est plus faible, et rembourser l'emprunt en empochant la différence. En revanche, si votre agent fait une mauvaise affaire, et doit vider son portefeuille pour rembourser l'emprunt, vous perdez automatiquement (`terminated=True`).\n",
    "\n",
    "### Actions continues\n",
    "\n",
    "Par rapport à l'environnement `gym-trading-env` d'origine, la version que je vous fournis permet de spécifier directement une position comme action, c'est-à-dire un nombre flottant. Votre agent a donc un contrôle précis sur la position désirée. Cela rajoute de la flexibilité mais rend l'apprentissage beaucoup plus difficile.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:25.119019Z",
     "start_time": "2025-12-22T09:47:24.861494Z"
    }
   },
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "# On veut une position de 88% ETH / 12% USD\n",
    "obs, reward, terminated, truncated, info = env.step(0.88)\n",
    "print(obs)\n",
    "print(info)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9692127   0.88        0.87977463]\n",
      "{'idx': 1, 'step': 1, 'date': np.datetime64('2023-11-21T15:30:00.000000000'), 'position_index': None, 'position': 0.88, 'real_position': np.float64(0.8797746150018296), 'data_open': 190.35000610351562, 'data_low': 189.74000549316406, 'data_high': 190.47000122070312, 'data_close': 189.94200134277344, 'data_volume': 5681421, 'data_date_close': Timestamp('2023-11-21 16:30:00'), 'portfolio_valuation': np.float64(997.359276756731), 'portfolio_distribution_asset': np.float64(4.6195752783697825), 'portfolio_distribution_fiat': np.float64(119.90790302957475), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(-0.002644216103365779)}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, l'espace des actions est limité à $[-1, 2]$ pour que votre agent ne puisse emprunter que jusqu'à 100%. Vous pouvez empêcher votre agent de prendre de telles positions, ou limiter le risque, en contrôlant les bornes autorisées des actions.\n",
    "\n",
    "Par exemple, en clippant l'action dans l'intervalle $[0,1]$, vous empêchez l'agent de faire des emprunts.\n",
    "\n",
    "À l'inverse, vous pouvez augmenter l'intervalle pour permettre des emprunts plus risqués, mais qui peuvent rapporter plus. À vous de choisir !\n",
    "\n",
    "Vous pouvez changer les bornes via le paramètre `position_range` du constructeur :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:25.301705Z",
     "start_time": "2025-12-22T09:47:25.130933Z"
    }
   },
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    position_range=(0, 1),  # ICI : (borne min, borne max)\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi modifier l'action en sortie de votre algorithme d'apprentissage, de la manière que vous souhaitez (clipping, interpolation, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions discrètes\n",
    "\n",
    "Pour simplifier l'apprentissage, vous pouvez utiliser le *wrapper* `gym_trading_env.wrapper.DiscreteActionsWrapper` que je vous fournis, et qui permet de revenir au fonctionnement d'origine de l'environnement `gym-trading-env`. Vous devrez alors spécifier l'ensemble des positions possibles, puis votre agent choisira une position parmi cette liste à chaque pas de temps.\n",
    "Par exemple, si la liste des positions est `[0, 0.5, 1]` et que l'action choisie est `1`, cela veut dire qu'on veut la position qui correspond au 2e élément de la liste, soit `0.5` (50%/50%).\n",
    "\n",
    "Vous pouvez rajouter autant d'actions que vous voulez, par exemple `[0, 0.25, 0.5, 1]` ou encore tous les 0.1 entre 0 et 1, etc. Plus il y a d'actions possibles, plus votre agent aura de choix (flexibilité), donc plus son comportement pourra être complexe, mais cela rajoute de la difficulté durant l'entraînement.\n",
    "\n",
    "N'oubliez pas que vous pouvez autoriser les positions avec emprunt en ajoutant des nombres inférieurs à 0 ou supérieurs à 1 à la liste autorisée.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:25.478393Z",
     "start_time": "2025-12-22T09:47:25.311957Z"
    }
   },
   "source": [
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "\n",
    "# Vous pouvez aussi appeler le wrapper `env` pour faire plus simple\n",
    "# Ici, je fais explicitement la distinction entre `wrapper` et `env`\n",
    "wrapper = DiscreteActionsWrapper(env, positions=[-1, 0, 0.25, 0.5, 0.75, 1, 2])\n",
    "obs, _ = wrapper.reset()\n",
    "# On veut une position de 25% ETH / 75% USD ; cela correspond à la position\n",
    "# d'index 2 dans la liste ci-dessus\n",
    "obs, reward, terminated, truncated, info = wrapper.step(2)\n",
    "print(obs)\n",
    "print(info)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.691366    0.25        0.25039366]\n",
      "{'idx': 1, 'step': 1, 'date': np.datetime64('2023-11-21T14:00:00.000000000'), 'position_index': 2, 'position': 0.25, 'real_position': np.float64(0.2503936737643807), 'data_open': 7216.89990234375, 'data_low': 7216.89990234375, 'data_high': 7234.830078125, 'data_close': 7231.89013671875, 'data_volume': 0, 'data_date_close': Timestamp('2023-11-21 15:00:00'), 'portfolio_valuation': np.float64(1000.1504441153436), 'portfolio_distribution_asset': np.float64(0.03462875393358), 'portfolio_distribution_fiat': np.float64(749.7191000962257), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(0.00015043279976245777)}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que, quand les actions continues sont utilisées, la variable `position_index` du dictionnaire `info` n'est pas disponible (c'est logique)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changement de la fonction de récompense\n",
    "\n",
    "Vous pouvez changer la fonction de récompense pour améliorer l'apprentissage de l'agent.\n",
    "Dans tous les cas, vous serez évalué(e)s sur la valuation du portefeuille à la fin de l'épisode (voir [ci-dessous](#évaluation)), mais cette simple mesure n'est peut-être pas la meilleure fonction de récompense.\n",
    "D'autres fonctions peuvent encourager l'agent à mieux apprendre, en explorant diverses possibilités, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:25.710195Z",
     "start_time": "2025-12-22T09:47:25.485577Z"
    }
   },
   "source": [
    "def reward_function(history):\n",
    "    return history['portfolio_valuation', -1]\n",
    "\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    # On spécifie la fonction de récompense\n",
    "    reward_function=reward_function,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déroulément d'un épisode\n",
    "\n",
    "Un épisode se déroule jusqu'à ce que :\n",
    "\n",
    "- l'agent atteigne la fin des données d'entraînement (nous n'avons plus de nouvelle donnée) => `truncated=True`\n",
    "\n",
    "- la valeur du portefeuille atteint 0 (l'agent a perdu tout l'argent) => `terminated=True`\n",
    "\n",
    "Vous devrez probablement entraîner l'agent sur plusieurs épisodes avant que son comportement ne converge.\n",
    "\n",
    "Pour éviter de sur-apprendre (*overfit*), vous devrez utiliser plusieurs jeux de données via [MultiDatasetTradingEnv](https://gym-trading-env.readthedocs.io/en/latest/multi_datasets.html).\n",
    "\n",
    "Dans ce cas, chaque épisode utilisera un jeu de données différent (en bouclant si vous demandez plus d'épisodes qu'il n'y a de jeux de données). Vous pouvez accéder au nom du jeu de données de l'épisode en cours via `env.name`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:28.152748Z",
     "start_time": "2025-12-22T09:47:25.719637Z"
    }
   },
   "source": [
    "nb_episodes = 2\n",
    "for episode in range(1, nb_episodes + 1):\n",
    "    obs, _ = env.reset()\n",
    "    print(f'Episode n˚{episode} -- Jeu de donnée {env.name}')\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    if terminated:\n",
    "        print('Argent perdu')\n",
    "    elif truncated:\n",
    "        print('Épisode terminé')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode n˚1 -- Jeu de donnée binance-ETHUSD-1h.pkl\n",
      "Market Return : 904.05%   |   Portfolio Return : -100.00%   |   \n",
      "Épisode terminé\n",
      "Episode n˚2 -- Jeu de donnée yfinance-STOXX50-1h.pkl\n",
      "Market Return : 27.70%   |   Portfolio Return : -98.47%   |   \n",
      "Épisode terminé\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation\n",
    "\n",
    "Afin de disposer d'un critère simple pour comparer les différentes solutions, nous utiliserons la valeur du portefeuille (`portfolio_valuation`).\n",
    "C'est assez simple : on veut que l'agent ait gagné le plus d'argent à la fin de la simulation.\n",
    "\n",
    "Vous pouvez ajouter ce critère à la liste des métriques affichées à la fin de chaque épisode, pour que ce soit plus visible :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:30.306074Z",
     "start_time": "2025-12-22T09:47:28.161675Z"
    }
   },
   "source": [
    "def metric_portfolio_valuation(history):\n",
    "    return round(history['portfolio_valuation', -1], 2)\n",
    "\n",
    "env.add_metric('Portfolio Valuation', metric_portfolio_valuation)\n",
    "\n",
    "done = False\n",
    "obs, _ = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Return : 163.91%   |   Portfolio Return : -100.00%   |   Portfolio Valuation : 0.0   |   \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque l'environnement peut se dérouler sur plusieurs épisodes (1 par jeu de données), vous devrez calculer la **moyenne des `portfolio_valuation`** sur l'ensemble des jeux de données possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Pour que ce soit honnête, vous **devez initialiser l'environnement avec les contraintes** imposées dans le sujet :\n",
    "\n",
    "- une valeur initiale du portefeuille de `1000` ;\n",
    "- des frais de 0.1% par transaction ;\n",
    "- un taux d'intérêt de 0.02% par jour soit 0.02/100/24 par heure.\n",
    "\n",
    "Sinon, il est beaucoup plus simple d'augmenter la valeur finale...\n",
    "\n",
    "```py\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    # LIGNES SUIVANTES :\n",
    "    # Valeur initiale du portefeuille\n",
    "    portfolio_initial_value=1_000,\n",
    "    # Frais de transactions\n",
    "    trading_fees=0.1/100,\n",
    "    # Intérêts sur les prêts\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")\n",
    "```\n",
    "\n",
    "Vous pouvez également accéder à la métrique de `portfolio_valuation` à la fin d'une simulation, si vous voulez par exemple l'ajouter à votre *run* WandB :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:47:30.485755Z",
     "start_time": "2025-12-22T09:47:30.315578Z"
    }
   },
   "source": [
    "portfolio_valuation = env.historical_info['portfolio_valuation', -1]\n",
    "# Si on avait WandB :\n",
    "# run.summary['portfolio_valuation'] = portfolio_valuation\n",
    "# On simule ça par un simple print...\n",
    "print(portfolio_valuation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.929165601714467e-18\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou bien, pour récupérer les métriques calculées par l'environnement (cela peut être utile pour les ajouter à WandB) :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:48:20.247321Z",
     "start_time": "2025-12-22T09:48:20.062750Z"
    }
   },
   "source": [
    "metrics = env.get_metrics()\n",
    "print(metrics)\n",
    "portfolio_valuation = metrics['Portfolio Valuation']\n",
    "print(portfolio_valuation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Market Return': '163.91%', 'Portfolio Return': '-100.00%', 'Portfolio Valuation': np.float64(0.0)}\n",
      "0.0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conseils\n",
    "\n",
    "À part les quelques contraintes présentées dans ce fichier (et rappelées sur la page du projet), vous êtes assez libres !\n",
    "\n",
    "Votre algorithme de RL peut être arbitrairement simple ou complexe. Je liste ici quelques conseils ou pistes, que vous pouvez explorer :\n",
    "\n",
    "- *Features* : Par défaut, votre agent n'utilise que le prix de l'*asset* (`close`) comme *feature* pour la prise de décision. Vous pouvez ajouter les *features* que vous voulez. En particulier, des métriques spécifiques à la finance peuvent être intéressantes, par exemple pour déterminer le risque que le prix change brutalement (à la hausse ou à la baisse)...\n",
    "\n",
    "- Algorithme : Vous pouvez utiliser des algorithmes existants, ou en inventer un nouveau. N'hésitez pas à ré-utiliser tout ce que vous avez appris en *Machine Learning* et *Deep Learning*. Typiquement, les données financières sont des données temporelles : certains réseaux de neurones sont plus appropriés que d'autres pour ce genre de tâche...\n",
    "\n",
    "- Configuration de l'environnement : L'environnement est très extensible ! Vous pouvez par exemple ajouter des *features* dynamiques (pas seulement calculées lors du prétraitement). La [documentation](https://gym-trading-env.readthedocs.io/en/latest/index.html) est très claire et très complète.\n",
    "\n",
    "Vous pouvez vous inspirer de travaux existants trouvés sur l'Internet à condition de **citer votre source**. Utiliser le travail de quelqu'un d'autre sans le citer sera considéré comme du plagiat."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Version aléatoire complète avec RSI et MACD, et visualisation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:30:01.574350Z",
     "start_time": "2025-12-18T16:30:01.570528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import gym_trading_env\n",
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Définition des indicateurs techniques"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:30:03.157984Z",
     "start_time": "2025-12-18T16:30:03.154211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(series, slow=26, fast=12, signal=9):\n",
    "    exp1 = series.ewm(span=fast, adjust=False).mean()\n",
    "    exp2 = series.ewm(span=slow, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    return macd"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Prétraitement des données"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:30:04.950275Z",
     "start_time": "2025-12-18T16:30:04.946006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(df):\n",
    "    # Tri et nettoyage\n",
    "    df = df.sort_index().dropna().drop_duplicates()\n",
    "\n",
    "    # Ajout de features (doivent commencer par \"feature_\")\n",
    "    # 1. RSI normalisé entre 0 et 1\n",
    "    df['feature_RSI'] = calculate_rsi(df['close']) / 100\n",
    "\n",
    "    # 2. MACD\n",
    "    df['feature_MACD'] = calculate_macd(df['close'])\n",
    "\n",
    "    # 3. Rendements logarithmiques (plus stable pour le RL que le prix brut)\n",
    "    df['feature_log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "    # 4. Position du prix par rapport à la moyenne mobile\n",
    "    df['feature_sma_dist'] = (df['close'] - df['close'].rolling(20).mean()) / df['close'].rolling(20).std()\n",
    "\n",
    "    return df.dropna()"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Configuration de l'environnement"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:30:09.335707Z",
     "start_time": "2025-12-18T16:30:09.331322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reward_function(history):\n",
    "    # Récompense basée sur la variation logarithmique de la valeur du portefeuille\n",
    "    # Cela encourage une croissance stable plutôt que des paris risqués\n",
    "    if len(history[\"portfolio_valuation\"]) < 2:\n",
    "        return 0\n",
    "    return np.log(history['portfolio_valuation', -1] / history['portfolio_valuation', -2])"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:30:10.334013Z",
     "start_time": "2025-12-18T16:30:10.310777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Création de l'environnement avec les contraintes du projet\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"./data/*.pkl\", # Assure-toi que le dossier data contient tes fichiers .pkl\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    reward_function=reward_function,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Exécution d'une simulation (Exemple avec un agent aléatoire)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:30:16.138871Z",
     "start_time": "2025-12-18T16:30:15.815748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Démarrage de la simulation sur le dataset : {env.unwrapped.name}\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "while not (done or truncated):\n",
    "    # Ici, tu remplaceras par : action, _states = model.predict(obs) si tu utilises Stable Baselines\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, truncated, info = env.step(action)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la simulation sur le dataset : binance-ETHUSD-1h.pkl\n",
      "Market Return : 26.85%   |   Portfolio Return : -98.80%   |   \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Visualisation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:11:22.094075Z",
     "start_time": "2025-12-17T15:06:52.972542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gym_trading_env.renderer import Renderer\n",
    "\n",
    "print(\"Sauvegarde des logs pour la visualisation...\")\n",
    "env.unwrapped.save_for_render(dir=\"render_logs\")\n",
    "\n",
    "print(\"Simulation terminée.\")\n",
    "print(f\"Valeur finale du portefeuille : {info['portfolio_valuation']:.2f}$\")\n",
    "\n",
    "renderer = Renderer(render_logs_dir=\"render_logs\")\n",
    "renderer.run()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde des logs pour la visualisation...\n",
      "Simulation terminée.\n",
      "Valeur finale du portefeuille : 0.00$\n",
      " * Serving Flask app 'gym_trading_env.renderer'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Version avec Stable Baselines3 et PPO"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Création de l'environnement d'entraînement"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:11:22.225482Z",
     "start_time": "2025-12-17T15:11:22.126767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"./data/*.pkl\",\n",
    "    preprocess=preprocess, # Ta fonction avec RSI, MACD, etc.\n",
    "    portfolio_initial_value=1000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    reward_function=reward_function,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Création de l'agent PPO avec MLP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:11:27.384978Z",
     "start_time": "2025-12-17T15:11:22.237684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=0.0003, # Hyperparamètre à ajuster\n",
    "    gamma=0.99,           # Facteur de réduction\n",
    "    tensorboard_log=\"./ppo_tensorboard/\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Apprentissage"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:13:28.302500Z",
     "start_time": "2025-12-17T15:11:27.394877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Entraînement en cours...\")\n",
    "model.learn(total_timesteps=100000) # Augmente ce chiffre pour de meilleures performances\n",
    "model.save(\"mon_agent_trading\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement en cours...\n",
      "Logging to ./ppo_tensorboard/PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2123 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1229         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046373173 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -2.24        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.021        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 0.0129       |\n",
      "------------------------------------------\n",
      "Market Return : 26.85%   |   Portfolio Return : -98.24%   |   \n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.49e+03     |\n",
      "|    ep_rew_mean          | -4.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1132         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041011823 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.631       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.017       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 0.00291      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49e+03    |\n",
      "|    ep_rew_mean          | -4.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003893129 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -2.82       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0047      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.000189    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49e+03    |\n",
      "|    ep_rew_mean          | -4.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1073        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008212082 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -2          |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0211      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 2.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49e+03    |\n",
      "|    ep_rew_mean          | -4.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1059        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008135519 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -1.3        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00211     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 1.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49e+03    |\n",
      "|    ep_rew_mean          | -4.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1048        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008183884 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.767      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 1.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49e+03    |\n",
      "|    ep_rew_mean          | -4.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1030        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007419682 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -0.61       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00792    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 1.86e-05    |\n",
      "-----------------------------------------\n",
      "Market Return :  5.83%   |   Portfolio Return : -99.99%   |   \n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.43e+03   |\n",
      "|    ep_rew_mean          | -6.63      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 970        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01208798 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | -0.727     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00874   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 0.771      |\n",
      "|    value_loss           | 1.31e-05   |\n",
      "----------------------------------------\n",
      "Market Return : 43.55%   |   Portfolio Return : -87.96%   |   \n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 927          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056488896 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -0.468       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.014        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    std                  | 0.774        |\n",
      "|    value_loss           | 0.000116     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 898         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003465272 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | -0.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00114    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    std                  | 0.767       |\n",
      "|    value_loss           | 0.000252    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 876         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047767 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.342      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.007      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    std                  | 0.754       |\n",
      "|    value_loss           | 0.000348    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 860          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037377747 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | -0.0868      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0166       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 0.747        |\n",
      "|    value_loss           | 0.000742     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 827          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025126315 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | -0.347       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00992      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.744        |\n",
      "|    value_loss           | 0.000662     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 813          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030524177 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0266       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.745        |\n",
      "|    value_loss           | 0.00131      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 805          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057697436 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | -0.28        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000988     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.737        |\n",
      "|    value_loss           | 0.000447     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 791          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038723918 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.024       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0133      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.722        |\n",
      "|    value_loss           | 0.000292     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 791          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046001086 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.0656      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0159       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000675    |\n",
      "|    std                  | 0.71         |\n",
      "|    value_loss           | 0.000529     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 789         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008677521 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0785     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00332     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    std                  | 0.687       |\n",
      "|    value_loss           | 0.000721    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 792          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041186805 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.0537      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00391      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.679        |\n",
      "|    value_loss           | 0.000659     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 794          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037960382 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.114       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0057       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.677        |\n",
      "|    value_loss           | 0.000438     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 798          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032743837 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.308       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00482     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000232    |\n",
      "|    std                  | 0.674        |\n",
      "|    value_loss           | 0.000229     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 802          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051246556 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -0.0459      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0154      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    std                  | 0.663        |\n",
      "|    value_loss           | 0.000166     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 805          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028793695 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.999       |\n",
      "|    explained_variance   | -0.384       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0197       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000206    |\n",
      "|    std                  | 0.651        |\n",
      "|    value_loss           | 8.07e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 807          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041606827 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.992       |\n",
      "|    explained_variance   | -0.0605      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00691     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    std                  | 0.656        |\n",
      "|    value_loss           | 0.000107     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 811         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004915081 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.992      |\n",
      "|    explained_variance   | -0.171      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 0.000237    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 814         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004521642 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | -0.113      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00947     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.649       |\n",
      "|    value_loss           | 0.000323    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 817          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031662318 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.984       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00254      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.646        |\n",
      "|    value_loss           | 0.000382     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 819         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004184693 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.975      |\n",
      "|    explained_variance   | -0.0434     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00264    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000901   |\n",
      "|    std                  | 0.636       |\n",
      "|    value_loss           | 0.000226    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78e+03    |\n",
      "|    ep_rew_mean          | -5.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 821         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002867326 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | -0.0549     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00347    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    std                  | 0.625       |\n",
      "|    value_loss           | 0.000465    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.78e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 824          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042154007 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | -0.0269      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000385    |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    std                  | 0.612        |\n",
      "|    value_loss           | 0.000513     |\n",
      "------------------------------------------\n",
      "Market Return : 926.72%   |   Portfolio Return : -100.00%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+04    |\n",
      "|    ep_rew_mean          | -9.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 824         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007935609 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | -0.0342     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    std                  | 0.597       |\n",
      "|    value_loss           | 0.000435    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 826          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038850892 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00645     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    std                  | 0.592        |\n",
      "|    value_loss           | 0.00314      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 827          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056295926 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000636    |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.585        |\n",
      "|    value_loss           | 0.00571      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 828          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065729767 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.872       |\n",
      "|    explained_variance   | -0.0986      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0148       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.575        |\n",
      "|    value_loss           | 0.0015       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 826          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024171195 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.871       |\n",
      "|    explained_variance   | -0.0255      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0126      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.582        |\n",
      "|    value_loss           | 0.000837     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+04    |\n",
      "|    ep_rew_mean          | -9.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 828         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002441635 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | -0.0527     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00681     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000533   |\n",
      "|    std                  | 0.591       |\n",
      "|    value_loss           | 0.000612    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 829          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030492968 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | -0.0635      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0148      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.586        |\n",
      "|    value_loss           | 0.000891     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 830          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020493204 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | -0.0486      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000787    |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000966    |\n",
      "|    std                  | 0.585        |\n",
      "|    value_loss           | 0.000573     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+04    |\n",
      "|    ep_rew_mean          | -9.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 831         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002020946 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | -0.0616     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00693    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.000249   |\n",
      "|    std                  | 0.599       |\n",
      "|    value_loss           | 0.00133     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+04    |\n",
      "|    ep_rew_mean          | -9.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 832         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005421549 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | -0.0275     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00151    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    std                  | 0.587       |\n",
      "|    value_loss           | 0.000844    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 833          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037111307 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.888       |\n",
      "|    explained_variance   | -0.118       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0207       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.589        |\n",
      "|    value_loss           | 0.000722     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.61e+04   |\n",
      "|    ep_rew_mean          | -9.08      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 834        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00535897 |\n",
      "|    clip_fraction        | 0.0693     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.887     |\n",
      "|    explained_variance   | -0.056     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0405    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    std                  | 0.586      |\n",
      "|    value_loss           | 0.000154   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 835          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026889779 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.881       |\n",
      "|    explained_variance   | -0.0657      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00569      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000992    |\n",
      "|    std                  | 0.582        |\n",
      "|    value_loss           | 0.000173     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 836          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027366371 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.869       |\n",
      "|    explained_variance   | -0.0244      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0124      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    std                  | 0.571        |\n",
      "|    value_loss           | 0.000412     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+04    |\n",
      "|    ep_rew_mean          | -9.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 836         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004670746 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | -0.0039     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 0.00153     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 837          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037304764 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.85        |\n",
      "|    explained_variance   | -0.00607     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0078      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    std                  | 0.568        |\n",
      "|    value_loss           | 0.000575     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+04     |\n",
      "|    ep_rew_mean          | -9.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 837          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046687936 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.855       |\n",
      "|    explained_variance   | -0.0113      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00194     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.568        |\n",
      "|    value_loss           | 0.000476     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+04    |\n",
      "|    ep_rew_mean          | -9.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 838         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004948006 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | -0.0185     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000163    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.000123    |\n",
      "|    std                  | 0.569       |\n",
      "|    value_loss           | 0.00219     |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ## 4. Évaluation et Visualisation sur un épisode"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:13:29.433049Z",
     "start_time": "2025-12-17T15:13:28.351287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Évaluation de l'agent entraîné...\")\n",
    "obs, info = env.reset()\n",
    "done, truncated = False, False\n",
    "\n",
    "while not (done or truncated):\n",
    "    # L'agent utilise maintenant son expérience pour choisir l'action\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation de l'agent entraîné...\n",
      "Market Return : 39.93%   |   Portfolio Return : -38.29%   |   \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Visualisation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:25:50.464182Z",
     "start_time": "2025-12-17T15:13:33.926317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env.unwrapped.save_for_render(dir=\"render_logs\")\n",
    "renderer = Renderer(render_logs_dir=\"render_logs\")\n",
    "renderer.run()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'gym_trading_env.renderer'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Dec/2025 16:13:36] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:13:37] \"GET /update_data/yfinance-GOLDUSD-1h.pkl_2025-12-17_14-21-49.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:13:38] \"GET /metrics HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:13:44] \"GET /update_data/yfinance-GOLDUSD-1h.pkl_2025-12-17_14-13-08.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:13:44] \"GET /metrics HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:14:20] \"GET /update_data/binance-DOGEEUR-1h.pkl_2025-12-17_14-13-11.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:14:20] \"GET /metrics HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:15:59] \"GET /update_data/yfinance-GOLDUSD-1h.pkl_2025-12-17_14-13-08.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 16:15:59] \"GET /metrics HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T16:03:46.124239Z",
     "start_time": "2025-12-17T16:03:45.996846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df= pd.read_pickle('./render_logs/yfinance-GOLDUSD-1h.pkl_2025-12-17_14-21-49.pkl')\n",
    "df.head()\n",
    "df.columns\n",
    "df.position.unique()\n",
    "df[\"position\"] = df.position.astype(float)\n",
    "df.to_pickle('./render_logs/yfinance-GOLDUSD-1h.pkl_2025-12-17_14-21-49.pkl')"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RecurrentPPO + Gestion du Risque"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T16:30:19.152455Z",
     "start_time": "2025-12-17T16:28:33.956805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import gym_trading_env\n",
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from gym_trading_env.renderer import Renderer\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Preprocess (On garde tes indicateurs) ---\n",
    "def preprocess(df):\n",
    "    df = df.sort_index().dropna().drop_duplicates()\n",
    "    df['feature_close'] = df['close'].pct_change()\n",
    "    df['feature_rsi'] = calculate_rsi(df['close']) / 100\n",
    "    df['feature_macd'] = calculate_macd(df['close'])\n",
    "    return df.dropna()\n",
    "\n",
    "# --- 2. Nouvelle fonction de récompense stricte ---\n",
    "def reward_function(history):\n",
    "    # 1. Calcul du rendement réel du portefeuille (frais inclus par l'env)\n",
    "    current_val = history['portfolio_valuation', -1]\n",
    "    prev_val = history['portfolio_valuation', -2]\n",
    "\n",
    "    # Rendement logarithmique\n",
    "    reward = np.log(current_val / prev_val)\n",
    "\n",
    "    # 2. PÉNALITÉ DE CHANGEMENT (Anti-Churning)\n",
    "    # Si l'agent change de position, il paie des frais.\n",
    "    # On ajoute une punition supplémentaire pour l'inciter à \"Hold\".\n",
    "    current_pos = history['position', -1]\n",
    "    prev_pos = history['position', -2]\n",
    "\n",
    "    if current_pos != prev_pos:\n",
    "        # On lui enlève artificiellement un peu plus de reward\n",
    "        # pour qu'il ne trade que si c'est vraiment nécessaire\n",
    "        reward -= 0.0005\n",
    "\n",
    "    return reward\n",
    "\n",
    "# --- 3. Création de l'environnement de base ---\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"./data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    reward_function=reward_function,\n",
    ")\n",
    "\n",
    "# --- 4. LE WRAPPER DISCRET (La solution miracle) ---\n",
    "env = DiscreteActionsWrapper(env, positions=[-0.25, 0, 1, 0.25,  0.5, 0.75])\n",
    "\n",
    "# --- 5. Agent PPO ---\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=0.0003,\n",
    "    ent_coef=0.01, # Encourage l'exploration pour ne pas rester bloqué sur 0\n",
    "    tensorboard_log=\"./ppo_discrete_tensorboard/\"\n",
    ")\n",
    "\n",
    "print(\"Entraînement en mode 'Sécurité' (Actions Discrètes)...\")\n",
    "model.learn(total_timesteps=100_000)\n",
    "model.save(\"ppo_discrete_safe\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Entraînement en mode 'Sécurité' (Actions Discrètes)...\n",
      "Logging to ./ppo_discrete_tensorboard/PPO_11\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2070 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1387        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011655919 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -7.74       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0551     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.00338     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1260         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057387836 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | -0.0333      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00195     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 0.00125      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1198        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009449073 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.034      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.000341    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1159        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012168355 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00333    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    value_loss           | 0.000526    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1132        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007876229 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.0748     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0301     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 0.000344    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1103        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008519396 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.00245     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00052    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 0.000547    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008501366 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -0.104      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    value_loss           | 0.000227    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1076        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008638654 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -0.009      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    value_loss           | 0.000467    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1062         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111564025 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.00726      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0242      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00998     |\n",
      "|    value_loss           | 0.0002       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1053         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074418127 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | -0.00925     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00698     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 0.000311     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1046        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009937004 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    value_loss           | 0.000156    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1040        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012362852 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -0.00214    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00927    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 8.44e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1033        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007891335 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00488    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 0.000132    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1030        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008080019 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.0124     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0212     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    value_loss           | 0.000621    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1024        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008740723 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.0174     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00829    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.000282    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1020        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005512801 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | -0.0232     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00725    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    value_loss           | 0.000293    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1016        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004751698 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    value_loss           | 0.00089     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1013         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065140845 |\n",
      "|    clip_fraction        | 0.0755       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | -0.0135      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.025       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 0.000579     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1010       |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00615934 |\n",
      "|    clip_fraction        | 0.0455     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.00587    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00992   |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.00421   |\n",
      "|    value_loss           | 0.000383   |\n",
      "----------------------------------------\n",
      "Market Return : 278.54%   |   Portfolio Return : -100.00%   |   \n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.21e+04     |\n",
      "|    ep_rew_mean          | -29.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1004         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073458804 |\n",
      "|    clip_fraction        | 0.0491       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.0121       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0295      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 0.000439     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.21e+04    |\n",
      "|    ep_rew_mean          | -29.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1002        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005662188 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | -0.0167     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00682    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    value_loss           | 0.000183    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.21e+04    |\n",
      "|    ep_rew_mean          | -29.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1000        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009717681 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | -0.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 7.24e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.21e+04    |\n",
      "|    ep_rew_mean          | -29.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 997         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008094577 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | -0.0304     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 6.57e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.21e+04    |\n",
      "|    ep_rew_mean          | -29.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 991         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005245432 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 7.46e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.21e+04     |\n",
      "|    ep_rew_mean          | -29.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 989          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033011157 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | -0.0126      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0143      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00911     |\n",
      "|    value_loss           | 1.31e-05     |\n",
      "------------------------------------------\n",
      "Market Return :  5.54%   |   Portfolio Return : -70.23%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.72e+04    |\n",
      "|    ep_rew_mean          | -16.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 987         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003016037 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | -0.0104     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    value_loss           | 9.36e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.72e+04    |\n",
      "|    ep_rew_mean          | -16.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 986         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026118625 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.73       |\n",
      "|    explained_variance   | -0.272      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0705     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 0.00762     |\n",
      "-----------------------------------------\n",
      "Market Return : 43.52%   |   Portfolio Return : -52.66%   |   \n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.93e+04   |\n",
      "|    ep_rew_mean          | -11.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 984        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04414931 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | -0.259     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0256     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00718   |\n",
      "|    value_loss           | 0.0083     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+04     |\n",
      "|    ep_rew_mean          | -11.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 980          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149987405 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | -0.403       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0257      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00871     |\n",
      "|    value_loss           | 0.00115      |\n",
      "------------------------------------------\n",
      "Market Return : 26.96%   |   Portfolio Return : -65.75%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 978         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037598617 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -0.197      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0531     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    value_loss           | 0.000293    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+04   |\n",
      "|    ep_rew_mean          | -9.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 977        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02015137 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | -1.19      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00418   |\n",
      "|    value_loss           | 8.15e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 976         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163742 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.282      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0398     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    value_loss           | 0.000121    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+04   |\n",
      "|    ep_rew_mean          | -9.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 975        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 71         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00760536 |\n",
      "|    clip_fraction        | 0.0757     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | -0.203     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0182    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00309   |\n",
      "|    value_loss           | 0.000252   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 974          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061962493 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.285       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0106      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 0.000217     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 973         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006033156 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.0594     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.000232    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 972         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006378724 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -0.129      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00365    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    value_loss           | 0.000136    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 972         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027341817 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.603      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.000189    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 972         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369278 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.151      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00241    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    value_loss           | 0.00014     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+04   |\n",
      "|    ep_rew_mean          | -9.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 971        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00446322 |\n",
      "|    clip_fraction        | 0.0461     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.958     |\n",
      "|    explained_variance   | -0.0576    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0208    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 0.00027    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 971         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004766279 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | -0.00538    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00559     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    value_loss           | 0.000112    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 971          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050664824 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.845       |\n",
      "|    explained_variance   | 0.0325       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00307     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 0.00081      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 970          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050733453 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.865       |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0131      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 0.000115     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 970          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035584867 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.792       |\n",
      "|    explained_variance   | -0.143       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0225      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 0.000187     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 969         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006472834 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    value_loss           | 8.27e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 968          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033588195 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.656       |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 7.45e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -9.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 968         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003703033 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00814    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    value_loss           | 0.000127    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 967          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025878157 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.799       |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0298      |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 0.000164     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -9.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 963          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035711676 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0144      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 0.000235     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T16:39:00.936736Z",
     "start_time": "2025-12-17T16:30:23.337566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 6. Visualisation ---\n",
    "print(\"Lancement de la simulation...\")\n",
    "obs, info = env.reset()\n",
    "done, truncated = False, False\n",
    "\n",
    "while not (done or truncated):\n",
    "    action, _ = model.predict(obs)\n",
    "\n",
    "    # --- CORRECTION ---\n",
    "    # On force la conversion du tableau numpy vers un entier Python standard\n",
    "    action = int(action)\n",
    "    # ------------------\n",
    "\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "# Sauvegarde\n",
    "env.unwrapped.save_for_render(dir=\"render_logs\")\n",
    "renderer = Renderer(render_logs_dir=\"render_logs\")\n",
    "renderer.run()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la simulation...\n",
      "Market Return : 914.64%   |   Portfolio Return : -99.46%   |   \n",
      " * Serving Flask app 'gym_trading_env.renderer'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Dec/2025 17:30:55] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 17:30:55] \"GET /update_data/yfinance-S&P500-1h.pkl_2025-12-17_17-27-29.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2025 17:30:55] \"GET /metrics HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Solution Hybride & Anti-Short Bias"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:27:38.036843Z",
     "start_time": "2025-12-22T09:22:52.273504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import gym_trading_env\n",
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from gym_trading_env.renderer import Renderer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# --- 1. CONFIGURATION ET INDICATEURS ---\n",
    "\n",
    "# On définit les hyperparamètres ici pour que WandB puisse les enregistrer\n",
    "config = {\n",
    "    \"policy_type\": \"MlpPolicy\",\n",
    "    \"total_timesteps\": 200_000,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"ent_coef\": 0.02, # Coefficient d'exploration\n",
    "    \"batch_size\": 128,\n",
    "    \"positions\": [-0.5, 0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5], # Hybride\n",
    "    \"project_name\": \"RL-Trading-Project\"\n",
    "}\n",
    "\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(series, slow=26, fast=12, signal=9):\n",
    "    exp1 = series.ewm(span=fast, adjust=False).mean()\n",
    "    exp2 = series.ewm(span=slow, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    return macd\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.sort_index().dropna().drop_duplicates()\n",
    "    df['feature_close'] = df['close'].pct_change()\n",
    "    df['feature_rsi'] = calculate_rsi(df['close']) / 100\n",
    "    df['feature_macd'] = calculate_macd(df['close'])\n",
    "    return df.dropna()\n",
    "\n",
    "def reward_function(history):\n",
    "    current_val = history['portfolio_valuation', -1]\n",
    "    prev_val = history['portfolio_valuation', -2]\n",
    "    reward = np.log(current_val / prev_val)\n",
    "\n",
    "    # Malus pour les positions Short (pour éviter le biais négatif)\n",
    "    if history['position', -1] < 0:\n",
    "        reward -= 0.0002\n",
    "\n",
    "    return reward\n",
    "\n",
    "# --- 2. INITIALISATION DE WANDB ---\n",
    "run = wandb.init(\n",
    "    project=config[\"project_name\"],\n",
    "    config=config,\n",
    "    sync_tensorboard=True, # Synchronise automatiquement les logs SB3\n",
    "    monitor_gym=True,      # Essaie d'enregistrer les vidéos (si disponible)\n",
    "    save_code=True,        # Sauvegarde ce script dans WandB\n",
    ")\n",
    "\n",
    "# --- 3. CRÉATION DE L'ENVIRONNEMENT ---\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"./data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    reward_function=reward_function,\n",
    ")\n",
    "\n",
    "# Wrapper Hybride (Int -> Float spécifique)\n",
    "env = DiscreteActionsWrapper(env, positions=config[\"positions\"])\n",
    "\n",
    "# --- 4. ENTRAÎNEMENT AVEC CALLBACK WANDB ---\n",
    "model = PPO(\n",
    "    config[\"policy_type\"],\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    ent_coef=config[\"ent_coef\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    tensorboard_log=f\"runs/{run.id}\" # Dossier unique pour Tensorboard\n",
    ")\n",
    "\n",
    "print(f\"Lancement de l'entraînement WandB : {run.name}\")\n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        gradient_save_freq=100,\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=2,\n",
    "    )\n",
    ")\n",
    "model.save(\"ppo_trading_wandb_final\")\n",
    "\n",
    "# --- 5. ÉVALUATION ET LOGGING FINAL ---\n",
    "print(\"Évaluation finale...\")\n",
    "obs, info = env.reset()\n",
    "done, truncated = False, False\n",
    "\n",
    "while not (done or truncated):\n",
    "    action, _ = model.predict(obs)\n",
    "    action = int(action) # Conversion array -> int pour le wrapper\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "# Récupération des métriques finales de l'environnement\n",
    "final_metrics = env.unwrapped.get_metrics()\n",
    "print(\"Métriques finales :\", final_metrics)\n",
    "\n",
    "# Envoi des métriques clés à WandB (pour le tableau de bord)\n",
    "wandb.log({\n",
    "    \"final_portfolio_valuation\": info['portfolio_valuation'],\n",
    "    \"market_return\": final_metrics.get(\"Market Return\", 0),\n",
    "    \"portfolio_return\": final_metrics.get(\"Portfolio Return\", 0)\n",
    "})\n",
    "\n",
    "# --- 6. VISUALISATION ---\n",
    "env.unwrapped.save_for_render(dir=\"render_logs\")\n",
    "\n",
    "# On ferme le run WandB proprement\n",
    "wandb.finish()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: arthur-collignon (arthur-collignon-cpe-lyon) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "28059a5d68d09833e057b175c8e6f535"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\arthu\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\wandb\\run-20251222_102305-n6etkjbb</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/n6etkjbb' target=\"_blank\">firm-lake-9</a></strong> to <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/n6etkjbb' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/n6etkjbb</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Lancement de l'entraînement WandB : firm-lake-9\n",
      "Logging to runs/n6etkjbb\\PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1066 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 890         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804827 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | -1.94       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0623     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 856          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058260746 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | -0.912       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0524      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 0.000921     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 851         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016322557 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | -0.138      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0573     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.000625    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 848         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009327846 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | -0.0562     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.06       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    value_loss           | 0.000748    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 845         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014085172 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | -0.0501     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0516     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.000409    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 839         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011707492 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.0407      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0548     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    value_loss           | 0.000195    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 838         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014230181 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | -0.0206     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 0.000341    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 838         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011849841 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | -0.00635    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    value_loss           | 0.000397    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 836         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008902974 |\n",
      "|    clip_fraction        | 0.0719      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | -0.068      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0525     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 0.000249    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 817         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987293 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | -0.0749     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 0.000239    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 813         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006573932 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | -0.373      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    value_loss           | 0.000151    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 809         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006360944 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | -0.043      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0516     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    value_loss           | 0.000198    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 809          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069777467 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | -0.0208      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0262      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    value_loss           | 0.000114     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 808         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010407645 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | -0.0425     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0469     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.000151    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 805         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012395858 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -0.0587     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0504     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 0.000172    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 803         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010824578 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0398     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.061      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 0.000364    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 803         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012230464 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.202      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0475     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    value_loss           | 0.000251    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 803         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010947522 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.0678     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0345     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    value_loss           | 0.000138    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 797         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007787288 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.108      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0451     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    value_loss           | 0.000181    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 797          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060469573 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | -0.107       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0428      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 0.00028      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 797          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062513524 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | -0.0213      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0313      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 0.00011      |\n",
      "------------------------------------------\n",
      "Market Return : 715.19%   |   Portfolio Return : -100.00%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.62e+04    |\n",
      "|    ep_rew_mean          | -32.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 797         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012892865 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.00488     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.000107    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.62e+04    |\n",
      "|    ep_rew_mean          | -32.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 798         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008161675 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.00586     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0691     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "Market Return : 39.25%   |   Portfolio Return : -79.88%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+04    |\n",
      "|    ep_rew_mean          | -16.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 798         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448575 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.0943     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0753     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.000395    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+04    |\n",
      "|    ep_rew_mean          | -16.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 798         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009648962 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.0663     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0545     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 6.34e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+04    |\n",
      "|    ep_rew_mean          | -16.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 799         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012736981 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.182      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0629     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 8.2e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+04    |\n",
      "|    ep_rew_mean          | -16.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 798         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012576023 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.066      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 6.25e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+04    |\n",
      "|    ep_rew_mean          | -16.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 799         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011629768 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -0.102      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0755     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 1.03e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.49e+04   |\n",
      "|    ep_rew_mean          | -16.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 798        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01454411 |\n",
      "|    clip_fraction        | 0.0999     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -0.0694    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0533    |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 1.39e-05   |\n",
      "----------------------------------------\n",
      "Market Return :  5.54%   |   Portfolio Return : -99.49%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.07e+04    |\n",
      "|    ep_rew_mean          | -13         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 797         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015134383 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.0304     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 1.55e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.07e+04     |\n",
      "|    ep_rew_mean          | -13          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 798          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060829488 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | -0.206       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0337      |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 0.000222     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.07e+04    |\n",
      "|    ep_rew_mean          | -13         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 798         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014958885 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -0.741      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 4.8e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.07e+04    |\n",
      "|    ep_rew_mean          | -13         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 799         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023227679 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -1.86       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.038      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 1.79e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.07e+04     |\n",
      "|    ep_rew_mean          | -13          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 799          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068218308 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | -0.304       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0319      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 5.62e-05     |\n",
      "------------------------------------------\n",
      "Market Return : 103.41%   |   Portfolio Return : -86.90%   |   \n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+04     |\n",
      "|    ep_rew_mean          | -10.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 799          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045869546 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.0336       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0309      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 0.000163     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+04     |\n",
      "|    ep_rew_mean          | -10.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 799          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064320825 |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.993       |\n",
      "|    explained_variance   | 0.0868       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0398      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    value_loss           | 0.000124     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+04     |\n",
      "|    ep_rew_mean          | -10.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 798          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051839584 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.0356      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0204      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 0.00014      |\n",
      "------------------------------------------\n",
      "Market Return : 26.96%   |   Portfolio Return : -66.57%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 795         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004897679 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.0878      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.000217    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004391785 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.0091      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0224     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 0.00341     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008717248 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 791         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009537701 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.049      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0372     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 0.00201     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -8.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 790          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034375575 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.0522      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0259      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 0.00144      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 789         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009776672 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.00468     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 0.000934    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013504188 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.0025     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013304049 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 0.000844    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010176781 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.0154     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010554511 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 0.000536    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -8.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119604375 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | -0.00363     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0349      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    value_loss           | 0.000652     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013819948 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.00395     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0294     |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 0.000311    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011046123 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.0801     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00883    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    value_loss           | 0.000195    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+04   |\n",
      "|    ep_rew_mean          | -8.45      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 786        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01285579 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.00202    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0269    |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.0057    |\n",
      "|    value_loss           | 0.000368   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011408107 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.0133     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0573     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -8.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101957405 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | -0.0151      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00869     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 0.000548     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009341892 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.000597   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    value_loss           | 0.000488    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -8.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066979043 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.51        |\n",
      "|    explained_variance   | 0.000183     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0278      |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 0.00184      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+04     |\n",
      "|    ep_rew_mean          | -8.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116860615 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | -0.0435      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0376      |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    value_loss           | 0.00117      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+04    |\n",
      "|    ep_rew_mean          | -8.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007637688 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    value_loss           | 0.000627    |\n",
      "-----------------------------------------\n",
      "Market Return : 278.54%   |   Portfolio Return : -100.00%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009771485 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.047      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    value_loss           | 0.000733    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+04      |\n",
      "|    ep_rew_mean          | -8.81      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 785        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01581797 |\n",
      "|    clip_fraction        | 0.0886     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | -0.242     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0488    |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.0083    |\n",
      "|    value_loss           | 0.000635   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009569693 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -0.602      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    value_loss           | 0.000323    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+04        |\n",
      "|    ep_rew_mean          | -8.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042162966 |\n",
      "|    clip_fraction        | 0.0542       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | -0.0144      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0338      |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    value_loss           | 0.00137      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+04        |\n",
      "|    ep_rew_mean          | -8.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 785          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053327936 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.00186      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0481      |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    value_loss           | 0.00239      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+04      |\n",
      "|    ep_rew_mean          | -8.81      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 786        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00704958 |\n",
      "|    clip_fraction        | 0.0825     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.0198     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0289    |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.00564   |\n",
      "|    value_loss           | 0.0015     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+04        |\n",
      "|    ep_rew_mean          | -8.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057348814 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -0.021       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00544     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 0.000917     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004777562 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.00117    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    value_loss           | 0.000857    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007298385 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.0522     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 0.000451    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004494067 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.0246     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 0.00127     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006562748 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.021      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.000464    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+04      |\n",
      "|    ep_rew_mean          | -8.81      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 786        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 182        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00679035 |\n",
      "|    clip_fraction        | 0.0608     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | -0.0281    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0404    |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.00765   |\n",
      "|    value_loss           | 0.000441   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+04        |\n",
      "|    ep_rew_mean          | -8.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077474145 |\n",
      "|    clip_fraction        | 0.0727       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -0.0819      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0357      |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    value_loss           | 0.000433     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+04      |\n",
      "|    ep_rew_mean          | -8.81      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 786        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00813608 |\n",
      "|    clip_fraction        | 0.0757     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | -0.00259   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0145    |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.00642   |\n",
      "|    value_loss           | 0.000269   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008924119 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.122      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0586     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 7.58e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005986999 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0368     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 0.000182    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006833894 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    value_loss           | 0.000327    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099174 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.0388     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0424     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    value_loss           | 0.000414    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+04        |\n",
      "|    ep_rew_mean          | -8.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 787          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069217505 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.125       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0343      |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    value_loss           | 0.000453     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+04        |\n",
      "|    ep_rew_mean          | -8.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 787          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067661554 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0401      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0096      |\n",
      "|    value_loss           | 0.000416     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -8.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007915027 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0369     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 0.000744    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+04      |\n",
      "|    ep_rew_mean          | -8.81      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 787        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 208        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00637379 |\n",
      "|    clip_fraction        | 0.0606     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | -0.0411    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0389    |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.00911   |\n",
      "|    value_loss           | 0.00106    |\n",
      "----------------------------------------\n",
      "Market Return : 914.64%   |   Portfolio Return : -100.00%   |   \n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+04     |\n",
      "|    ep_rew_mean          | -9.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 787          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078116213 |\n",
      "|    clip_fraction        | 0.0626       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.0322       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.024       |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 0.000555     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+04     |\n",
      "|    ep_rew_mean          | -9.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068342825 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -0.0125      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0369      |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 0.000348     |\n",
      "------------------------------------------\n",
      "Market Return :  9.60%   |   Portfolio Return : -74.56%   |   \n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.11e+04     |\n",
      "|    ep_rew_mean          | -8.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066822683 |\n",
      "|    clip_fraction        | 0.0768       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.0716      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.017       |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 0.00014      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.11e+04    |\n",
      "|    ep_rew_mean          | -8.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009224422 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.105      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0348     |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    value_loss           | 7.87e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.11e+04     |\n",
      "|    ep_rew_mean          | -8.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070655975 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.0252      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0252      |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    value_loss           | 6.21e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.11e+04     |\n",
      "|    ep_rew_mean          | -8.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062617613 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.0186      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0336      |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    value_loss           | 5.02e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.11e+04    |\n",
      "|    ep_rew_mean          | -8.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005674331 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.0415      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0398     |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    value_loss           | 5.15e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.11e+04     |\n",
      "|    ep_rew_mean          | -8.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 229          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057795914 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.0564      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0294      |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00665     |\n",
      "|    value_loss           | 8.88e-05     |\n",
      "------------------------------------------\n",
      "Market Return : 103.41%   |   Portfolio Return : -79.46%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+04       |\n",
      "|    ep_rew_mean          | -7.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005726307 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0345     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 0.000106    |\n",
      "-----------------------------------------\n",
      "Market Return : 43.52%   |   Portfolio Return : -47.95%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+04    |\n",
      "|    ep_rew_mean          | -6.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005694086 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.987      |\n",
      "|    explained_variance   | -0.00205    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0358     |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    value_loss           | 0.000119    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+04     |\n",
      "|    ep_rew_mean          | -6.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042611146 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -0.0557      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0201      |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    value_loss           | 0.000194     |\n",
      "------------------------------------------\n",
      "Market Return : 26.96%   |   Portfolio Return : -56.82%   |   \n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+04    |\n",
      "|    ep_rew_mean          | -6.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005743636 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.00119    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    value_loss           | 0.000117    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+04     |\n",
      "|    ep_rew_mean          | -6.35        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 785          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030916894 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.0641       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0354      |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 0.000116     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+04     |\n",
      "|    ep_rew_mean          | -6.35        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 785          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056125117 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.011        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.045       |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 0.000417     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+04    |\n",
      "|    ep_rew_mean          | -6.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011139032 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -0.0522     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0522     |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+04    |\n",
      "|    ep_rew_mean          | -6.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005655345 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0504      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0463     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 0.000638    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+04    |\n",
      "|    ep_rew_mean          | -6.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005229772 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.134      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 0.000582    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+04    |\n",
      "|    ep_rew_mean          | -6.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007094186 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -0.0249     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0536     |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    value_loss           | 0.000392    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Linked 1 file into the W&B run directory (hardlinks); call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation finale...\n",
      "Market Return :  9.60%   |   Portfolio Return : -64.89%   |   \n",
      "Métriques finales : {'Market Return': ' 9.60%', 'Portfolio Return': '-64.89%'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "bd8738a567cfe891f519959bc36e7549"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>final_portfolio_valuation</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>rollout/ep_len_mean</td><td>██▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>time/fps</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/approx_kl</td><td>▃▆▄▃▂▃▃▂▂▃▄▂█▁▂▁▁▃▃▄▅▄▂▄▃▂▂▂▃▃▂▃▂▃▂▂▂▂▂▂</td></tr><tr><td>train/clip_fraction</td><td>▂▄▄▄▄▁▂▅▃▃▅▅█▇▄▃▂▁▂▂▃▁▁▃▅▃▂▂▂▃▃▅▃▄▄▂▃▂▅▃</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▁▁▁▁▂▂▂▂▂▂▄█▇▇▆▆▅▅▅▄▄▄▄▇▆▇▇▆▅▆▆▅▆▅▇█▇▃▃</td></tr><tr><td>train/explained_variance</td><td>▁███▆█▇███▇▇▇▅▁█████████▆█▇██████▇██████</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>final_portfolio_valuation</td><td>351.1391</td></tr><tr><td>global_step</td><td>200704</td></tr><tr><td>market_return</td><td> 9.60%</td></tr><tr><td>portfolio_return</td><td>-64.89%</td></tr><tr><td>rollout/ep_len_mean</td><td>17125</td></tr><tr><td>rollout/ep_rew_mean</td><td>-6.34999</td></tr><tr><td>time/fps</td><td>785</td></tr><tr><td>train/approx_kl</td><td>0.00709</td></tr><tr><td>train/clip_fraction</td><td>0.04541</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-lake-9</strong> at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/n6etkjbb' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/n6etkjbb</a><br> View project at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a><br>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251222_102305-n6etkjbb\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:40:57.036413Z",
     "start_time": "2025-12-22T09:27:45.979163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lancement du renderer local\n",
    "renderer = Renderer(render_logs_dir=\"render_logs\")\n",
    "renderer.run()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'gym_trading_env.renderer'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [22/Dec/2025 10:27:50] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2025 10:27:50] \"GET /update_data/yfinance-S&P500-1h.pkl_2025-12-17_17-42-49.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2025 10:27:50] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Dec/2025 10:27:51] \"GET /metrics HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent : RecurentPPO"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:48:40.446678Z",
     "start_time": "2025-12-22T09:48:36.276006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import gym_trading_env\n",
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "from gym_trading_env.renderer import Renderer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# Vous aurez besoin de cette librairie pour le LSTM\n",
    "# !pip install sb3-contrib\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "\n",
    "# --- 1. CONFIGURATION (WandB) ---\n",
    "config = {\n",
    "    \"policy_type\": \"MlpLstmPolicy\",  # Changement majeur : LSTM\n",
    "    \"total_timesteps\": 500_000,      # Un peu plus long pour le LSTM\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "    \"n_steps\": 2048,\n",
    "    \"window_size\": 20,               # Fenêtre d'observation pour le LSTM\n",
    "    \"positions\": [0, 0.5, 1.0],      # Simplifié au début : Cash, Moitié, Full (Pas de levier/short risqué)\n",
    "    \"project_name\": \"RL-Trading-Project\",\n",
    "    \"run_name\": \"RecurrentPPO_Optimized\"\n",
    "}\n",
    "\n",
    "# --- 2. FONCTIONS DE TRAITEMENT ---\n",
    "\n",
    "def calculate_indicators(df):\n",
    "    # RSI\n",
    "    delta = df['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['feature_rsi'] = 100 - (100 / (1 + rs))\n",
    "    df['feature_rsi'] = df['feature_rsi'] / 100.0 # Normalisé\n",
    "\n",
    "    # MACD\n",
    "    exp1 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['feature_macd'] = (exp1 - exp2) / df['close'] # Normalisé par le prix\n",
    "\n",
    "    # ATR (Volatilité) - Important pour la survie\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df['feature_atr'] = true_range.rolling(14).mean() / df['close']\n",
    "\n",
    "    # Returns\n",
    "    df['feature_return'] = df['close'].pct_change()\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.sort_index().dropna().drop_duplicates()\n",
    "    return calculate_indicators(df)\n",
    "\n",
    "def reward_function(history):\n",
    "    # Rendement logarithmique\n",
    "    current_val = history['portfolio_valuation', -1]\n",
    "    prev_val = history['portfolio_valuation', -2]\n",
    "    ret = np.log(current_val / prev_val)\n",
    "\n",
    "    # Pénalité de volatilité (Sharpe Ratio implicite)\n",
    "    # Cela calme l'agent pour éviter les -50%\n",
    "    risk_penalty = 0.1 * (ret ** 2)\n",
    "\n",
    "    return ret - risk_penalty\n",
    "\n",
    "# --- 3. INITIALISATION WANDB ---\n",
    "run = wandb.init(\n",
    "    project=config[\"project_name\"],\n",
    "    name=config[\"run_name\"],\n",
    "    config=config,\n",
    "    sync_tensorboard=True, # Synchronise les logs SB3 avec WandB\n",
    "    monitor_gym=True,\n",
    "    save_code=True,\n",
    ")\n",
    "\n",
    "# --- 4. CRÉATION DE L'ENVIRONNEMENT ---\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"./data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    reward_function=reward_function,\n",
    "    window_size=config[\"window_size\"] # Important pour le LSTM\n",
    ")\n",
    "\n",
    "env = DiscreteActionsWrapper(env, positions=config[\"positions\"])\n",
    "\n",
    "# --- 5. CRÉATION DU MODÈLE ET ENTRAÎNEMENT ---\n",
    "model = RecurrentPPO(\n",
    "    config[\"policy_type\"],\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    ent_coef=config[\"ent_coef\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    n_steps=config[\"n_steps\"],\n",
    "    # Log dans le dossier spécifique pour que WandB le trouve\n",
    "    tensorboard_log=f\"runs/{run.id}\"\n",
    ")\n",
    "\n",
    "print(f\"Lancement du run WandB : {run.name}\")\n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        gradient_save_freq=100,\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=2,\n",
    "    )\n",
    ")\n",
    "\n",
    "model.save(\"recurrent_ppo_final\")\n",
    "\n",
    "# --- 6. ÉVALUATION ET LOGGING FINAL ---\n",
    "print(\"Évaluation...\")\n",
    "obs, info = env.reset()\n",
    "done, truncated = False, False\n",
    "\n",
    "while not (done or truncated):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    action = int(action)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "# Envoi des métriques finales manuelles\n",
    "final_metrics = env.unwrapped.get_metrics()\n",
    "wandb.log({\n",
    "    \"final_portfolio_valuation\": info['portfolio_valuation'],\n",
    "    \"market_return\": final_metrics.get(\"Market Return\", 0),\n",
    "    \"portfolio_return\": final_metrics.get(\"Portfolio Return\", 0)\n",
    "})\n",
    "\n",
    "# Fin du run\n",
    "wandb.finish()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "5fddd4fdfb55f409571d43613b26e3a8"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RecurrentPPO_Optimized</strong> at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/hnjg50hi' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/hnjg50hi</a><br> View project at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a><br>Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251222_104439-hnjg50hi\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "800100f13d7784ec00faa31d84c083f2"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\arthu\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\wandb\\run-20251222_104836-2w7kj4xf</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/2w7kj4xf' target=\"_blank\">RecurrentPPO_Optimized</a></strong> to <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/2w7kj4xf' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/2w7kj4xf</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "ename": "TypeError",
     "evalue": "TradingEnv.__init__() got an unexpected keyword argument 'window_size' was raised from the environment creator for MultiDatasetTradingEnv with kwargs ({'dataset_dir': './data/*.pkl', 'preprocess': <function preprocess at 0x000001BBC3912200>, 'portfolio_initial_value': 1000, 'trading_fees': 0.001, 'borrow_interest_rate': 8.333333333333334e-06, 'reward_function': <function reward_function at 0x000001BBC39132E0>, 'window_size': 20})",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:734\u001B[39m, in \u001B[36mmake\u001B[39m\u001B[34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001B[39m\n\u001B[32m    733\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m734\u001B[39m     env = \u001B[43menv_creator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43menv_spec_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\gym_trading_env\\environments.py:390\u001B[39m, in \u001B[36mMultiDatasetTradingEnv.__init__\u001B[39m\u001B[34m(self, dataset_dir, preprocess, episodes_between_dataset_switch, *args, **kwargs)\u001B[39m\n\u001B[32m    389\u001B[39m \u001B[38;5;28mself\u001B[39m.dataset_nb_uses = np.zeros(shape=(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset_pathes), ))\n\u001B[32m--> \u001B[39m\u001B[32m390\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnext_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: TradingEnv.__init__() got an unexpected keyword argument 'window_size'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 84\u001B[39m\n\u001B[32m     74\u001B[39m run = wandb.init(\n\u001B[32m     75\u001B[39m     project=config[\u001B[33m\"\u001B[39m\u001B[33mproject_name\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     76\u001B[39m     name=config[\u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m     80\u001B[39m     save_code=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m     81\u001B[39m )\n\u001B[32m     83\u001B[39m \u001B[38;5;66;03m# --- 4. CRÉATION DE L'ENVIRONNEMENT ---\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m env = \u001B[43mgym\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     85\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mMultiDatasetTradingEnv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./data/*.pkl\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpreprocess\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpreprocess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m    \u001B[49m\u001B[43mportfolio_initial_value\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrading_fees\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m/\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[43m    \u001B[49m\u001B[43mborrow_interest_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.02\u001B[39;49m\u001B[43m/\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m/\u001B[49m\u001B[32;43m24\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     91\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreward_function\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreward_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwindow_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mwindow_size\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Important pour le LSTM\u001B[39;49;00m\n\u001B[32m     93\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m env = DiscreteActionsWrapper(env, positions=config[\u001B[33m\"\u001B[39m\u001B[33mpositions\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     97\u001B[39m \u001B[38;5;66;03m# --- 5. CRÉATION DU MODÈLE ET ENTRAÎNEMENT ---\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\.venv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:746\u001B[39m, in \u001B[36mmake\u001B[39m\u001B[34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001B[39m\n\u001B[32m    740\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m error.Error(\n\u001B[32m    741\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mYou passed render_mode=\u001B[39m\u001B[33m'\u001B[39m\u001B[33mhuman\u001B[39m\u001B[33m'\u001B[39m\u001B[33m although \u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_spec.id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m doesn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt implement human-rendering natively. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    742\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mGym tried to apply the HumanRendering wrapper but it looks like your environment is using the old \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    743\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mrendering API, which is not supported by the HumanRendering wrapper.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    744\u001B[39m         ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    745\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m746\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(e)(\n\u001B[32m    747\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m was raised from the environment creator for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_spec.id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m with kwargs (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_spec_kwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    748\u001B[39m         )\n\u001B[32m    750\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(env, gym.Env):\n\u001B[32m    751\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    752\u001B[39m         \u001B[38;5;28mstr\u001B[39m(env.\u001B[34m__class__\u001B[39m.__base__) == \u001B[33m\"\u001B[39m\u001B[33m<class \u001B[39m\u001B[33m'\u001B[39m\u001B[33mgym.core.Env\u001B[39m\u001B[33m'\u001B[39m\u001B[33m>\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    753\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(env.\u001B[34m__class__\u001B[39m.__base__) == \u001B[33m\"\u001B[39m\u001B[33m<class \u001B[39m\u001B[33m'\u001B[39m\u001B[33mgym.core.Wrapper\u001B[39m\u001B[33m'\u001B[39m\u001B[33m>\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    754\u001B[39m     ):\n",
      "\u001B[31mTypeError\u001B[39m: TradingEnv.__init__() got an unexpected keyword argument 'window_size' was raised from the environment creator for MultiDatasetTradingEnv with kwargs ({'dataset_dir': './data/*.pkl', 'preprocess': <function preprocess at 0x000001BBC3912200>, 'portfolio_initial_value': 1000, 'trading_fees': 0.001, 'borrow_interest_rate': 8.333333333333334e-06, 'reward_function': <function reward_function at 0x000001BBC39132E0>, 'window_size': 20})"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualisation locale\n",
    "env.unwrapped.save_for_render(dir=\"render_logs\")\n",
    "renderer = Renderer(render_logs_dir=\"render_logs\")\n",
    "renderer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
