2025-12-11 10:55:55,659 INFO    MainThread:32564 [wandb_setup.py:_flush():80] Current SDK version is 0.23.1
2025-12-11 10:55:55,659 INFO    MainThread:32564 [wandb_setup.py:_flush():80] Configure stats pid to 32564
2025-12-11 10:55:55,659 INFO    MainThread:32564 [wandb_setup.py:_flush():80] Loading settings from C:\Users\arthu\.config\wandb\settings
2025-12-11 10:55:55,659 INFO    MainThread:32564 [wandb_setup.py:_flush():80] Loading settings from C:\Users\arthu\Work\CPE\S9\ReinforcementLearning\Projet\wandb\settings
2025-12-11 10:55:55,659 INFO    MainThread:32564 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-12-11 10:55:55,659 INFO    MainThread:32564 [wandb_init.py:setup_run_log_directory():714] Logging user logs to C:\Users\arthu\Work\CPE\S9\ReinforcementLearning\Projet\wandb\run-20251211_105555-mk8jywuy\logs\debug.log
2025-12-11 10:55:55,660 INFO    MainThread:32564 [wandb_init.py:setup_run_log_directory():715] Logging internal logs to C:\Users\arthu\Work\CPE\S9\ReinforcementLearning\Projet\wandb\run-20251211_105555-mk8jywuy\logs\debug-internal.log
2025-12-11 10:55:55,660 INFO    MainThread:32564 [wandb_init.py:monkeypatch_ipython():633] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x000001FAC9365FD0>
2025-12-11 10:55:55,691 INFO    MainThread:32564 [wandb_init.py:init():841] calling init triggers
2025-12-11 10:55:55,691 INFO    MainThread:32564 [wandb_init.py:init():846] wandb.init called with sweep_config: {}
config: {'policy_type': 'MlpLstmPolicy', 'total_timesteps': 100000, 'env_id': 'MultiDatasetTradingEnv', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 128, 'ent_coef': 0.01, '_wandb': {'code_path': 'code/projet.ipynb'}}
2025-12-11 10:55:55,691 INFO    MainThread:32564 [wandb_init.py:init():889] starting backend
2025-12-11 10:55:58,351 INFO    MainThread:32564 [wandb_init.py:init():892] sending inform_init request
2025-12-11 10:55:58,395 INFO    MainThread:32564 [wandb_init.py:init():900] backend started and connected
2025-12-11 10:55:58,398 INFO    MainThread:32564 [wandb_run.py:_label_probe_notebook():1334] probe notebook
2025-12-11 10:55:58,399 INFO    MainThread:32564 [wandb_run.py:_label_probe_notebook():1344] Unable to probe notebook: 'charmap' codec can't decode byte 0x8f in position 25155: character maps to <undefined>
2025-12-11 10:55:58,399 INFO    MainThread:32564 [wandb_init.py:init():970] updated telemetry
2025-12-11 10:55:58,679 INFO    MainThread:32564 [wandb_init.py:init():994] communicating run to backend with 90.0 second timeout
2025-12-11 10:56:01,691 INFO    MainThread:32564 [wandb_init.py:init():1041] starting run threads in backend
2025-12-11 10:56:02,051 INFO    MainThread:32564 [wandb_run.py:_console_start():2521] atexit reg
2025-12-11 10:56:02,051 INFO    MainThread:32564 [wandb_run.py:_redirect():2369] redirect: wrap_raw
2025-12-11 10:56:02,052 INFO    MainThread:32564 [wandb_run.py:_redirect():2438] Wrapping output streams.
2025-12-11 10:56:02,052 INFO    MainThread:32564 [wandb_run.py:_redirect():2461] Redirects installed.
2025-12-11 10:56:02,074 INFO    MainThread:32564 [wandb_init.py:init():1081] run started, returning control to user process
2025-12-11 10:56:02,502 INFO    MainThread:32564 [wandb_run.py:_tensorboard_callback():1607] tensorboard callback: runs/mk8jywuy\RecurrentPPO_1, True
2025-12-11 10:56:02,532 INFO    MainThread:32564 [wandb_run.py:_config_callback():1396] config_cb None None {'algo': 'RecurrentPPO', 'policy_class': "<class 'sb3_contrib.common.recurrent.policies.RecurrentActorCriticPolicy'>", 'device': 'cpu', 'verbose': 0, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 100000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1765446962172292900, 'tensorboard_log': 'runs/mk8jywuy', '_last_obs': '[[-2.0309      0.07909152  0.07909152]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001FAAA889590>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-inf, inf, (3,), float32)', 'action_space': 'Box(-1.0, 1.0, (1,), float32)', 'n_envs': 1, 'gamma': 0.99, 'gae_lambda': 0.95, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': 'None', 'rollout_buffer_kwargs': '{}', 'n_epochs': 10, 'clip_range': 'FloatSchedule(ConstantSchedule(val=0.2))', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', '_last_lstm_states': 'RNNStates(pi=(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]])), vf=(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]])))', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'policy': 'RecurrentActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64, out_features=1, bias=True)\n  (value_net): Linear(in_features=64, out_features=1, bias=True)\n  (lstm_actor): LSTM(3, 256)\n  (lstm_critic): LSTM(3, 256)\n)', 'rollout_buffer': '<sb3_contrib.common.recurrent.buffers.RecurrentRolloutBuffer object at 0x000001FACAD2B9D0>', '_logger': '<stable_baselines3.common.logger.Logger object at 0x000001FAAB2C9A90>'}
2025-12-11 11:02:39,552 INFO    MainThread:32564 [wandb_run.py:_finish():2287] finishing run arthur-collignon-cpe-lyon/RL-Trading-Project/mk8jywuy
2025-12-11 11:02:39,621 INFO    MainThread:32564 [jupyter.py:save_history():464] saving 16 cells to _session_history.ipynb
2025-12-11 11:02:39,622 INFO    MainThread:32564 [wandb_run.py:_config_callback():1396] config_cb ('_wandb', 'session_history') code\_session_history.ipynb None
2025-12-11 11:02:39,630 INFO    MainThread:32564 [jupyter.py:_save_ipynb():371] looking for notebook: projet.ipynb
2025-12-11 11:02:41,551 INFO    MainThread:32564 [wandb_run.py:_config_callback():1396] config_cb None None {'_wandb': {'code_path': 'source-RL-Trading-Project-projet.ipynb'}}
2025-12-11 11:02:41,552 INFO    MainThread:32564 [wandb_init.py:_jupyter_teardown():617] saved code and history: <Artifact source-RL-Trading-Project-projet.ipynb>
2025-12-11 11:02:41,552 INFO    MainThread:32564 [wandb_init.py:_jupyter_teardown():618] cleaning up jupyter logic
2025-12-11 11:02:41,552 INFO    MainThread:32564 [wandb_run.py:_atexit_cleanup():2486] got exitcode: 0
2025-12-11 11:02:41,553 INFO    MainThread:32564 [wandb_run.py:_restore():2468] restore
2025-12-11 11:02:41,553 INFO    MainThread:32564 [wandb_run.py:_restore():2474] restore done
2025-12-11 11:02:44,974 INFO    MainThread:32564 [wandb_run.py:_footer_sync_info():3862] logging synced files
