{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL -- Projet \"Trading automatique\"\n",
    "\n",
    "Ce notebook contient du code de base et quelques explications pour vous aider sur ce sujet.\n",
    "\n",
    "Vous êtes libres de réaliser ce projet avec des scripts Python ou des Jupyter Notebooks, à votre convenance.\n",
    "\n",
    "Vous devez télécharger les paquets Python suivants :\n",
    "\n",
    "```sh\n",
    "pip install gymnasium\n",
    "pip install pandas\n",
    "pip install gym-trading-env-continuous\n",
    "```\n",
    "\n",
    "Vous utiliserez l'environnement `gym-trading-env-continuous`, qui est un *fork* de [Gym Trading Env](https://gym-trading-env.readthedocs.io/en/latest/index.html). La différence majeure est expliquée dans ce document ; la documentation originelle reste utilisable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.457425Z",
     "start_time": "2025-12-11T09:33:04.900982Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import gym_trading_env"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation des données de simulation\n",
    "\n",
    "Les données sont dans un format binaire (Pickle) que vous pouvez lire avec Pandas. Vous devez vous assurer que les données sont triées par date.\n",
    "\n",
    "Des étapes de prétraitement peuvent aider votre apprentissage, par exemple, supprimer les doublons, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.499527Z",
     "start_time": "2025-12-11T09:33:05.465013Z"
    }
   },
   "source": [
    "def preprocess(df):\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
    "df.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       open    high     low   close       volume  \\\n",
       "date_open                                                          \n",
       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
       "\n",
       "                             date_close  \n",
       "date_open                                \n",
       "2020-08-18 07:00:00 2020-08-18 08:00:00  \n",
       "2020-08-18 08:00:00 2020-08-18 09:00:00  \n",
       "2020-08-18 09:00:00 2020-08-18 10:00:00  \n",
       "2020-08-18 10:00:00 2020-08-18 11:00:00  \n",
       "2020-08-18 11:00:00 2020-08-18 12:00:00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_open</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-18 07:00:00</th>\n",
       "      <td>430.00</td>\n",
       "      <td>435.00</td>\n",
       "      <td>410.00</td>\n",
       "      <td>430.30</td>\n",
       "      <td>487.154463</td>\n",
       "      <td>2020-08-18 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 08:00:00</th>\n",
       "      <td>430.27</td>\n",
       "      <td>431.79</td>\n",
       "      <td>430.27</td>\n",
       "      <td>430.80</td>\n",
       "      <td>454.176153</td>\n",
       "      <td>2020-08-18 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 09:00:00</th>\n",
       "      <td>430.86</td>\n",
       "      <td>431.13</td>\n",
       "      <td>428.71</td>\n",
       "      <td>429.35</td>\n",
       "      <td>1183.710884</td>\n",
       "      <td>2020-08-18 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 10:00:00</th>\n",
       "      <td>429.75</td>\n",
       "      <td>432.69</td>\n",
       "      <td>428.59</td>\n",
       "      <td>431.90</td>\n",
       "      <td>1686.183227</td>\n",
       "      <td>2020-08-18 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 11:00:00</th>\n",
       "      <td>432.09</td>\n",
       "      <td>432.89</td>\n",
       "      <td>426.99</td>\n",
       "      <td>427.45</td>\n",
       "      <td>1980.692724</td>\n",
       "      <td>2020-08-18 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de *features*\n",
    "\n",
    "Vous pouvez également rajouter de nouvelles données au DataFrame pour créer de nouvelles *features* que l'agent pourra utiliser.\n",
    "Voir pour cela la [doc](https://gym-trading-env.readthedocs.io/en/latest/features.html).\n",
    "\n",
    "Chaque nouvelle *feature* doit commencer par `feature_` pour être détectée."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.543264Z",
     "start_time": "2025-12-11T09:33:05.508123Z"
    }
   },
   "source": [
    "def preprocess(df):\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df['feature_close'] = (df['close'] - df['close'].mean()) / df['close'].std()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
    "df.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       open    high     low   close       volume  \\\n",
       "date_open                                                          \n",
       "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
       "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
       "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
       "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
       "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
       "\n",
       "                             date_close  feature_close  \n",
       "date_open                                               \n",
       "2020-08-18 07:00:00 2020-08-18 08:00:00      -1.891634  \n",
       "2020-08-18 08:00:00 2020-08-18 09:00:00      -1.891128  \n",
       "2020-08-18 09:00:00 2020-08-18 10:00:00      -1.892594  \n",
       "2020-08-18 10:00:00 2020-08-18 11:00:00      -1.890016  \n",
       "2020-08-18 11:00:00 2020-08-18 12:00:00      -1.894514  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date_close</th>\n",
       "      <th>feature_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_open</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-18 07:00:00</th>\n",
       "      <td>430.00</td>\n",
       "      <td>435.00</td>\n",
       "      <td>410.00</td>\n",
       "      <td>430.30</td>\n",
       "      <td>487.154463</td>\n",
       "      <td>2020-08-18 08:00:00</td>\n",
       "      <td>-1.891634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 08:00:00</th>\n",
       "      <td>430.27</td>\n",
       "      <td>431.79</td>\n",
       "      <td>430.27</td>\n",
       "      <td>430.80</td>\n",
       "      <td>454.176153</td>\n",
       "      <td>2020-08-18 09:00:00</td>\n",
       "      <td>-1.891128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 09:00:00</th>\n",
       "      <td>430.86</td>\n",
       "      <td>431.13</td>\n",
       "      <td>428.71</td>\n",
       "      <td>429.35</td>\n",
       "      <td>1183.710884</td>\n",
       "      <td>2020-08-18 10:00:00</td>\n",
       "      <td>-1.892594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 10:00:00</th>\n",
       "      <td>429.75</td>\n",
       "      <td>432.69</td>\n",
       "      <td>428.59</td>\n",
       "      <td>431.90</td>\n",
       "      <td>1686.183227</td>\n",
       "      <td>2020-08-18 11:00:00</td>\n",
       "      <td>-1.890016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-18 11:00:00</th>\n",
       "      <td>432.09</td>\n",
       "      <td>432.89</td>\n",
       "      <td>426.99</td>\n",
       "      <td>427.45</td>\n",
       "      <td>1980.692724</td>\n",
       "      <td>2020-08-18 12:00:00</td>\n",
       "      <td>-1.894514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, l'agent ne reçoit comme *features* que sa dernière *position* (voir le paragraphe suivant), ce qui ne sera certainement pas suffisant ! À vous d'ajouter les *features* qui seront pertinentes pour que l'agent apprenne la politique optimale..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctionnement des actions\n",
    "\n",
    "Une action est une **position**, c'est-à-dire un ratio entre la proportion d'*assets* (exemple : ETH) et la proportion de *fiat* (exemple : USD) dans le portefeuille.\n",
    "Ainsi, la position `0.5` consiste à avoir exactement 50% d'ETH et 50% d'USD (en vendant l'un ou l'autre pour arriver à ce ratio). `0.1` consiste à avoir 10% d'ETH et 90% d'USD.\n",
    "\n",
    "Il existe des positions un peu plus complexes :\n",
    "\n",
    "- `< 0` : une position inférieure à 0 va vendre encore plus d'ETH que le portefeuille n'en contient, pour obtenir des USD. Cela nécessite un emprunt, qui sera remboursé avec un intérêt.\n",
    "- `> 1` : une position supérieure à 1 va dépenser encore plus d'USD que le portefeuille n'en contient, pour acheter des ETH. Cela nécessite également un emprunt.\n",
    "\n",
    "Ces positions (qui sont appelées *short* et *margin* en finance) peuvent faire gagner beaucoup à votre agent, mais démultiplient les risques également. Si votre agent fait une bonne affaire, vous pouvez vendre à un prix élevé, racheter quand le prix est plus faible, et rembourser l'emprunt en empochant la différence. En revanche, si votre agent fait une mauvaise affaire, et doit vider son portefeuille pour rembourser l'emprunt, vous perdez automatiquement (`terminated=True`).\n",
    "\n",
    "### Actions continues\n",
    "\n",
    "Par rapport à l'environnement `gym-trading-env` d'origine, la version que je vous fournis permet de spécifier directement une position comme action, c'est-à-dire un nombre flottant. Votre agent a donc un contrôle précis sur la position désirée. Cela rajoute de la flexibilité mais rend l'apprentissage beaucoup plus difficile.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.622272Z",
     "start_time": "2025-12-11T09:33:05.552640Z"
    }
   },
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "# On veut une position de 88% ETH / 12% USD\n",
    "obs, reward, terminated, truncated, info = env.step(0.88)\n",
    "print(obs)\n",
    "print(info)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1176176   0.88        0.86199826]\n",
      "{'idx': 1, 'step': 1, 'date': np.datetime64('2021-01-29T13:00:00.000000000'), 'position_index': None, 'position': 0.88, 'real_position': np.float64(0.8619982420158219), 'data_volume': 47022463.7, 'data_open': 0.05181, 'data_date_close': Timestamp('2021-01-29 14:00:00'), 'data_high': 0.05699, 'data_close': 0.04413, 'data_low': 0.042, 'portfolio_valuation': np.float64(868.8994655314681), 'portfolio_distribution_asset': np.float64(16972.35014223006), 'portfolio_distribution_fiat': np.float64(119.90965375485541), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(-0.14052785024653625)}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, l'espace des actions est limité à $[-1, 2]$ pour que votre agent ne puisse emprunter que jusqu'à 100%. Vous pouvez empêcher votre agent de prendre de telles positions, ou limiter le risque, en contrôlant les bornes autorisées des actions.\n",
    "\n",
    "Par exemple, en clippant l'action dans l'intervalle $[0,1]$, vous empêchez l'agent de faire des emprunts.\n",
    "\n",
    "À l'inverse, vous pouvez augmenter l'intervalle pour permettre des emprunts plus risqués, mais qui peuvent rapporter plus. À vous de choisir !\n",
    "\n",
    "Vous pouvez changer les bornes via le paramètre `position_range` du constructeur :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.654986Z",
     "start_time": "2025-12-11T09:33:05.630508Z"
    }
   },
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    position_range=(0, 1),  # ICI : (borne min, borne max)\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi modifier l'action en sortie de votre algorithme d'apprentissage, de la manière que vous souhaitez (clipping, interpolation, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions discrètes\n",
    "\n",
    "Pour simplifier l'apprentissage, vous pouvez utiliser le *wrapper* `gym_trading_env.wrapper.DiscreteActionsWrapper` que je vous fournis, et qui permet de revenir au fonctionnement d'origine de l'environnement `gym-trading-env`. Vous devrez alors spécifier l'ensemble des positions possibles, puis votre agent choisira une position parmi cette liste à chaque pas de temps.\n",
    "Par exemple, si la liste des positions est `[0, 0.5, 1]` et que l'action choisie est `1`, cela veut dire qu'on veut la position qui correspond au 2e élément de la liste, soit `0.5` (50%/50%).\n",
    "\n",
    "Vous pouvez rajouter autant d'actions que vous voulez, par exemple `[0, 0.25, 0.5, 1]` ou encore tous les 0.1 entre 0 et 1, etc. Plus il y a d'actions possibles, plus votre agent aura de choix (flexibilité), donc plus son comportement pourra être complexe, mais cela rajoute de la difficulté durant l'entraînement.\n",
    "\n",
    "N'oubliez pas que vous pouvez autoriser les positions avec emprunt en ajoutant des nombres inférieurs à 0 ou supérieurs à 1 à la liste autorisée.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.681956Z",
     "start_time": "2025-12-11T09:33:05.662301Z"
    }
   },
   "source": [
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "\n",
    "# Vous pouvez aussi appeler le wrapper `env` pour faire plus simple\n",
    "# Ici, je fais explicitement la distinction entre `wrapper` et `env`\n",
    "wrapper = DiscreteActionsWrapper(env, positions=[-1, 0, 0.25, 0.5, 0.75, 1, 2])\n",
    "obs, _ = wrapper.reset()\n",
    "# On veut une position de 25% ETH / 75% USD ; cela correspond à la position\n",
    "# d'index 2 dans la liste ci-dessus\n",
    "obs, reward, terminated, truncated, info = wrapper.step(2)\n",
    "print(obs)\n",
    "print(info)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16626613  0.25        0.25014377]\n",
      "{'idx': 1, 'step': 1, 'date': np.datetime64('2023-11-21T14:00:00.000000000'), 'position_index': 2, 'position': 0.25, 'real_position': np.float64(0.2501437786412375), 'data_volume': 0, 'data_open': 1.0949305295944214, 'data_date_close': Timestamp('2023-11-21 15:00:00'), 'data_high': 1.0961307287216187, 'data_close': 1.0955302715301514, 'data_low': 1.0948106050491333, 'portfolio_valuation': np.float64(1000.0093399728391), 'portfolio_distribution_asset': np.float64(228.33336647827292), 'portfolio_distribution_fiat': np.float64(749.8632249955033), 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0.0, 'portfolio_distribution_interest_fiat': 0.0, 'reward': np.float64(9.339929221864947e-06)}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que, quand les actions continues sont utilisées, la variable `position_index` du dictionnaire `info` n'est pas disponible (c'est logique)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changement de la fonction de récompense\n",
    "\n",
    "Vous pouvez changer la fonction de récompense pour améliorer l'apprentissage de l'agent.\n",
    "Dans tous les cas, vous serez évalué(e)s sur la valuation du portefeuille à la fin de l'épisode (voir [ci-dessous](#évaluation)), mais cette simple mesure n'est peut-être pas la meilleure fonction de récompense.\n",
    "D'autres fonctions peuvent encourager l'agent à mieux apprendre, en explorant diverses possibilités, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:05.745429Z",
     "start_time": "2025-12-11T09:33:05.688496Z"
    }
   },
   "source": [
    "def reward_function(history):\n",
    "    return history['portfolio_valuation', -1]\n",
    "\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    # On spécifie la fonction de récompense\n",
    "    reward_function=reward_function,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déroulément d'un épisode\n",
    "\n",
    "Un épisode se déroule jusqu'à ce que :\n",
    "\n",
    "- l'agent atteigne la fin des données d'entraînement (nous n'avons plus de nouvelle donnée) => `truncated=True`\n",
    "\n",
    "- la valeur du portefeuille atteint 0 (l'agent a perdu tout l'argent) => `terminated=True`\n",
    "\n",
    "Vous devrez probablement entraîner l'agent sur plusieurs épisodes avant que son comportement ne converge.\n",
    "\n",
    "Pour éviter de sur-apprendre (*overfit*), vous devrez utiliser plusieurs jeux de données via [MultiDatasetTradingEnv](https://gym-trading-env.readthedocs.io/en/latest/multi_datasets.html).\n",
    "\n",
    "Dans ce cas, chaque épisode utilisera un jeu de données différent (en bouclant si vous demandez plus d'épisodes qu'il n'y a de jeux de données). Vous pouvez accéder au nom du jeu de données de l'épisode en cours via `env.name`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:06.549346Z",
     "start_time": "2025-12-11T09:33:05.752216Z"
    }
   },
   "source": [
    "nb_episodes = 2\n",
    "for episode in range(1, nb_episodes + 1):\n",
    "    obs, _ = env.reset()\n",
    "    print(f'Episode n˚{episode} -- Jeu de donnée {env.name}')\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    if terminated:\n",
    "        print('Argent perdu')\n",
    "    elif truncated:\n",
    "        print('Épisode terminé')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode n˚1 -- Jeu de donnée yfinance-EURUSD-1h.pkl\n",
      "Market Return :  5.27%   |   Portfolio Return : -100.00%   |   \n",
      "Épisode terminé\n",
      "Episode n˚2 -- Jeu de donnée yfinance-AAPL-1h.pkl\n",
      "Market Return : 39.94%   |   Portfolio Return : -96.92%   |   \n",
      "Épisode terminé\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation\n",
    "\n",
    "Afin de disposer d'un critère simple pour comparer les différentes solutions, nous utiliserons la valeur du portefeuille (`portfolio_valuation`).\n",
    "C'est assez simple : on veut que l'agent ait gagné le plus d'argent à la fin de la simulation.\n",
    "\n",
    "Vous pouvez ajouter ce critère à la liste des métriques affichées à la fin de chaque épisode, pour que ce soit plus visible :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:06.773682Z",
     "start_time": "2025-12-11T09:33:06.555285Z"
    }
   },
   "source": [
    "def metric_portfolio_valuation(history):\n",
    "    return round(history['portfolio_valuation', -1], 2)\n",
    "\n",
    "env.add_metric('Portfolio Valuation', metric_portfolio_valuation)\n",
    "\n",
    "done = False\n",
    "obs, _ = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Return : 10.54%   |   Portfolio Return : -98.67%   |   Portfolio Valuation : 13.33   |   \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque l'environnement peut se dérouler sur plusieurs épisodes (1 par jeu de données), vous devrez calculer la **moyenne des `portfolio_valuation`** sur l'ensemble des jeux de données possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Pour que ce soit honnête, vous **devez initialiser l'environnement avec les contraintes** imposées dans le sujet :\n",
    "\n",
    "- une valeur initiale du portefeuille de `1000` ;\n",
    "- des frais de 0.1% par transaction ;\n",
    "- un taux d'intérêt de 0.02% par jour soit 0.02/100/24 par heure.\n",
    "\n",
    "Sinon, il est beaucoup plus simple d'augmenter la valeur finale...\n",
    "\n",
    "```py\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    # LIGNES SUIVANTES :\n",
    "    # Valeur initiale du portefeuille\n",
    "    portfolio_initial_value=1_000,\n",
    "    # Frais de transactions\n",
    "    trading_fees=0.1/100,\n",
    "    # Intérêts sur les prêts\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")\n",
    "```\n",
    "\n",
    "Vous pouvez également accéder à la métrique de `portfolio_valuation` à la fin d'une simulation, si vous voulez par exemple l'ajouter à votre *run* WandB :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:06.784809Z",
     "start_time": "2025-12-11T09:33:06.780582Z"
    }
   },
   "source": [
    "portfolio_valuation = env.historical_info['portfolio_valuation', -1]\n",
    "# Si on avait WandB :\n",
    "# run.summary['portfolio_valuation'] = portfolio_valuation\n",
    "# On simule ça par un simple print...\n",
    "print(portfolio_valuation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.32516244673074\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou bien, pour récupérer les métriques calculées par l'environnement (cela peut être utile pour les ajouter à WandB) :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:33:06.804983Z",
     "start_time": "2025-12-11T09:33:06.801548Z"
    }
   },
   "source": [
    "metrics = env.get_metrics()\n",
    "print(metrics)\n",
    "portfolio_valuation = metrics['Portfolio Valuation']\n",
    "print(portfolio_valuation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Market Return': '10.54%', 'Portfolio Return': '-98.67%', 'Portfolio Valuation': np.float64(13.33)}\n",
      "13.33\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conseils\n",
    "\n",
    "À part les quelques contraintes présentées dans ce fichier (et rappelées sur la page du projet), vous êtes assez libres !\n",
    "\n",
    "Votre algorithme de RL peut être arbitrairement simple ou complexe. Je liste ici quelques conseils ou pistes, que vous pouvez explorer :\n",
    "\n",
    "- *Features* : Par défaut, votre agent n'utilise que le prix de l'*asset* (`close`) comme *feature* pour la prise de décision. Vous pouvez ajouter les *features* que vous voulez. En particulier, des métriques spécifiques à la finance peuvent être intéressantes, par exemple pour déterminer le risque que le prix change brutalement (à la hausse ou à la baisse)...\n",
    "\n",
    "- Algorithme : Vous pouvez utiliser des algorithmes existants, ou en inventer un nouveau. N'hésitez pas à ré-utiliser tout ce que vous avez appris en *Machine Learning* et *Deep Learning*. Typiquement, les données financières sont des données temporelles : certains réseaux de neurones sont plus appropriés que d'autres pour ce genre de tâche...\n",
    "\n",
    "- Configuration de l'environnement : L'environnement est très extensible ! Vous pouvez par exemple ajouter des *features* dynamiques (pas seulement calculées lors du prétraitement). La [documentation](https://gym-trading-env.readthedocs.io/en/latest/index.html) est très claire et très complète.\n",
    "\n",
    "Vous pouvez vous inspirer de travaux existants trouvés sur l'Internet à condition de **citer votre source**. Utiliser le travail de quelqu'un d'autre sans le citer sera considéré comme du plagiat."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:29:19.094786Z",
     "start_time": "2025-12-11T10:29:19.086924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import gym_trading_env\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from stable_baselines3.common.utils import get_latest_run_id\n",
    "\n",
    "\n",
    "## ----------------------------------------------------------------------\n",
    "## A. FONCTIONS DE PRÉTRAITEMENT ET DE RÉCOMPENSE\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "def preprocess_v2(df):\n",
    "    df = df.sort_index().dropna().drop_duplicates()\n",
    "    # Log Returns\n",
    "    df[\"feature_log_returns\"] = np.log(df[\"close\"]).diff()\n",
    "    # Indicateurs de Volatilité (ATR simplifié)\n",
    "    df['tr1'] = df['high'] - df['low']\n",
    "    df['tr2'] = np.abs(df['high'] - df['close'].shift(1))\n",
    "    df['tr3'] = np.abs(df['low'] - df['close'].shift(1))\n",
    "    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)\n",
    "    df['feature_atr'] = df['tr'].rolling(window=14).mean() / df[\"close\"]\n",
    "    # Indicateurs de Tendance (MACD)\n",
    "    ema_fast = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_slow = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['feature_macd'] = ema_fast - ema_slow\n",
    "    df['feature_macd_signal'] = df['feature_macd'].ewm(span=9, adjust=False).mean()\n",
    "    # Indicateurs de Momentum (RSI)\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    # Normalisation finale\n",
    "    df['feature_rsi'] = 100 - (100 / (1 + rs)) / 100\n",
    "    df = df.dropna()\n",
    "    cols_to_normalize = ['feature_log_returns', 'feature_macd', 'feature_macd_signal', 'feature_atr']\n",
    "    for col in cols_to_normalize:\n",
    "        if df[col].std() > 0:\n",
    "            df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "        else:\n",
    "             df[col] = 0.0\n",
    "    return df\n",
    "\n",
    "def reward_function_v2(history):\n",
    "    # Log-Return différentiel\n",
    "    prev_val = history['portfolio_valuation', -2]\n",
    "    curr_val = history['portfolio_valuation', -1]\n",
    "    if prev_val == 0: return 0\n",
    "    reward = np.log(curr_val / prev_val)\n",
    "    return reward\n",
    "\n",
    "## ----------------------------------------------------------------------\n",
    "## B. CUSTOM CALLBACK WANDB (Métriques financières)\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "class CustomTradingCallback(BaseCallback):\n",
    "    def __init__(self, verbose: int = 0):\n",
    "        super().__init__(verbose)\n",
    "        self.episode_num = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.locals['dones'][0]:\n",
    "            self.episode_num += 1\n",
    "            raw_env = self.training_env.envs[0].unwrapped\n",
    "            metrics = raw_env.get_metrics()\n",
    "\n",
    "            # Récupération des retours pour le calcul de performance\n",
    "            market_return_str = metrics.get('Market Return', '0.00%').strip()\n",
    "            market_return = float(market_return_str.strip('%')) / 100\n",
    "            portfolio_return_str = metrics.get('Portfolio Return', '0.00%').strip()\n",
    "            portfolio_return = float(portfolio_return_str.strip('%')) / 100\n",
    "\n",
    "            if self.logger is not None:\n",
    "                self.logger.record(\"episode/final_portfolio_valuation\", metrics.get('Portfolio Valuation'))\n",
    "                self.logger.record(\"episode/return_vs_market_pct\", (portfolio_return - market_return) * 100)\n",
    "                self.logger.record(\"episode/total_portfolio_return_pct\", portfolio_return * 100)\n",
    "                self.logger.record(\"episode/market_return_pct\", market_return * 100)\n",
    "                self.logger.record(\"episode/steps\", raw_env.step) # CORRECTION : raw_env.step\n",
    "\n",
    "                self.logger.dump(step=self.num_timesteps)\n",
    "\n",
    "        return True"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chargement et Configuration"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:37:14.741771Z",
     "start_time": "2025-12-11T10:30:48.669936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. HYPERPARAMÈTRES ET CONFIGURATION GLOBALE ---\n",
    "config = {\n",
    "    \"policy_type\": \"MlpLstmPolicy\",\n",
    "    \"total_timesteps\": 100_000,\n",
    "    \"env_id\": \"MultiDatasetTradingEnv\",\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 128,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"portfolio_initial_value\": 1_000,\n",
    "    \"trading_fees\": 0.1/100,\n",
    "    \"borrow_interest_rate\": 0.02/100/24,\n",
    "    \"positions_range\": (-1, 1),\n",
    "    \"model_name\": \"mon_agent_trading\" # Nom de base pour la sauvegarde\n",
    "}\n",
    "\n",
    "# --- 2. INITIALISATION DE WANDB ET RÉCUPÉRATION DU CHEMIN DE SAUVEGARDE ---\n",
    "run = wandb.init(\n",
    "    project=\"RL-Trading-Project\",\n",
    "    entity=\"arthur-collignon-cpe-lyon\",\n",
    "    config=config,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym=True,\n",
    "    save_code=True,\n",
    ")\n",
    "\n",
    "# Chemin où SB3 sauvegardera le modèle (dans le dossier WandB)\n",
    "# Nous stockons ce chemin dans une variable globale pour le backtesting.\n",
    "MODEL_SAVE_PATH = f\"models/{run.id}/{config['model_name']}.zip\"\n",
    "WANDB_RUN_ID = run.id # Sauvegarde de l'ID du run actuel\n",
    "\n",
    "# --- 3. CRÉATION DE L'ENVIRONNEMENT ET DU MODÈLE ---\n",
    "env = gym.make(\n",
    "    config[\"env_id\"],\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess_v2,\n",
    "    reward_function=reward_function_v2,\n",
    "    position_range=config[\"positions_range\"],\n",
    "    portfolio_initial_value=config[\"portfolio_initial_value\"],\n",
    "    trading_fees=config[\"trading_fees\"],\n",
    "    borrow_interest_rate=config[\"borrow_interest_rate\"],\n",
    ")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = RecurrentPPO(\n",
    "    config[\"policy_type\"], env, verbose=0, **{k: config[k] for k in ['learning_rate', 'n_steps', 'batch_size', 'ent_coef']}\n",
    ")\n",
    "\n",
    "# --- 4. DÉFINITION DE LA LISTE DE CALLBACKS ---\n",
    "callback = CallbackList([\n",
    "    WandbCallback(\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=0,\n",
    "        model_save_freq=10000,\n",
    "        # Nom de fichier personnalisé (pour le rendre facilement chargeable)\n",
    "        # Note: ceci nécessite un hack pour s'assurer que le nom est constant\n",
    "        # La sauvegarde finale sera gérée manuellement.\n",
    "    ),\n",
    "    CustomTradingCallback(verbose=0),\n",
    "])\n",
    "\n",
    "# --- 5. ENTRAÎNEMENT ET SAUVEGARDE FINALE ---\n",
    "try:\n",
    "    print(\"Début de l'entraînement avec WandB...\")\n",
    "    model.learn(\n",
    "        total_timesteps=config[\"total_timesteps\"],\n",
    "        callback=callback,\n",
    "    )\n",
    "    # Sauvegarde finale manuelle dans le chemin exact\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    print(f\"Modèle sauvegardé dans : {MODEL_SAVE_PATH}\")\n",
    "finally:\n",
    "    run.finish()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "0d972e52fcc642407aa7a285c9d69a62"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\arthu\\Work\\CPE\\S9\\ReinforcementLearning\\Projet\\wandb\\run-20251211_113049-k9vxs8ed</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/k9vxs8ed' target=\"_blank\">ethereal-firebrand-6</a></strong> to <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/k9vxs8ed' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/k9vxs8ed</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement avec WandB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Linked 1 file into the W&B run directory (hardlinks); call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Return :  5.54%   |   Portfolio Return : -99.99%   |   \n",
      "Market Return : 278.54%   |   Portfolio Return : -100.00%   |   \n",
      "Market Return : 43.52%   |   Portfolio Return : -65.81%   |   \n",
      "Market Return : 103.41%   |   Portfolio Return : -93.95%   |   \n",
      "Modèle sauvegardé dans : models/k9vxs8ed/mon_agent_trading.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "75742baf3f98253f5eaf0eaa8a54702b"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-firebrand-6</strong> at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/k9vxs8ed' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project/runs/k9vxs8ed</a><br> View project at: <a href='https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project' target=\"_blank\">https://wandb.ai/arthur-collignon-cpe-lyon/RL-Trading-Project</a><br>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251211_113049-k9vxs8ed\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exécution du Backtest (La boucle de prédiction)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:41:12.111400Z",
     "start_time": "2025-12-11T10:41:11.996163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Nécessite matplotlib, numpy, pandas (déjà importés)\n",
    "\n",
    "# --- RAPPEL DU CHEMIN DE SAUVEGARDE (doit être exécuté après la section 2) ---\n",
    "# Si la section 2 a été exécutée, MODEL_SAVE_PATH et WANDB_RUN_ID sont définis.\n",
    "\n",
    "# Si le notebook a été redémarré, vous devez retrouver le chemin du dernier run :\n",
    "# Si vous voulez tester le dernier run, décommenter et exécuter cette recherche:\n",
    "# latest_run_dir = os.path.join(\"wandb\", \"latest-run\")\n",
    "# path_to_load = os.path.join(latest_run_dir, \"files\", \"models\", \"mon_agent_trading.zip\")\n",
    "# Sinon, utilisez le chemin stocké lors du run :\n",
    "path_to_load = MODEL_SAVE_PATH # Assurez-vous que cette variable est définie !\n",
    "\n",
    "\n",
    "# --- 1. Chargement de l'environnement de Test (Doit correspondre exactement à l'entraînement) ---\n",
    "env_test = gym.make(\n",
    "    config[\"env_id\"],\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess_v2,\n",
    "    reward_function=reward_function_v2,\n",
    "    position_range=config[\"positions_range\"],\n",
    "    portfolio_initial_value=config[\"portfolio_initial_value\"],\n",
    "    trading_fees=config[\"trading_fees\"],\n",
    "    borrow_interest_rate=config[\"borrow_interest_rate\"],\n",
    ")\n",
    "env_test = DummyVecEnv([lambda: env_test])\n",
    "\n",
    "# --- 2. Chargement de l'Agent depuis WandB ---\n",
    "try:\n",
    "    model = RecurrentPPO.load(path_to_load)\n",
    "    print(f\"Modèle chargé depuis : {path_to_load}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERREUR: Fichier modèle non trouvé à {path_to_load}.\")\n",
    "    print(\"Assurez-vous que l'entraînement s'est terminé et a bien sauvegardé le modèle.\")\n",
    "    # On arrête le backtest ici si le modèle n'est pas trouvé.\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. Exécution du Backtest ---\n",
    "obs, info = env_test.reset()\n",
    "_states = None\n",
    "done = False\n",
    "while not done:\n",
    "    # deterministic=True est CRUCIAL pour le test\n",
    "    action, _states = model.predict(obs, state=_states, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env_test.step(action)\n",
    "    done = terminated or truncated\n",
    "print(\"Backtest terminé.\")\n",
    "\n",
    "\n",
    "# --- 4. Analyse des Résultats et Visualisation ---\n",
    "raw_env = env_test.envs[0].unwrapped\n",
    "metrics = raw_env.get_metrics()\n",
    "df_results = raw_env.save_for_render(dir=f\"render_logs_{WANDB_RUN_ID}\")\n",
    "\n",
    "print(\"\\n--- RÉSULTATS DU BACKTEST ---\")\n",
    "print(f\"Valeur Finale du Portefeuille    : {metrics['Portfolio Valuation']:.2f} $\")\n",
    "print(f\"Rendement de l'Agent             : {metrics['Portfolio Return']}\")\n",
    "print(f\"Rendement du Marché (Buy & Hold) : {metrics['Market Return']}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "#\n",
    "# Comparaison Graphique\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_results.index, df_results['portfolio_valuation'], label='Agent AI', color='blue', linewidth=2)\n",
    "# Buy & Hold (normalisé au capital initial)\n",
    "initial_price = df_results['data_close'].iloc[0]\n",
    "initial_portfolio = df_results['portfolio_valuation'].iloc[0]\n",
    "factor = initial_portfolio / initial_price\n",
    "plt.plot(df_results.index, df_results['data_close'] * factor, label='Buy & Hold (Marché)', color='gray', linestyle='--', alpha=0.7)\n",
    "plt.title(\"Performance : Intelligence Artificielle vs Marché\")\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"Valeur du Portefeuille ($)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualisation des Positions\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(df_results.index, df_results['position'], label=\"Position de l'Agent\", color='orange')\n",
    "plt.title(\"Décisions de l'Agent au cours du temps\")\n",
    "plt.ylabel(\"Position (-1 = Short, 1 = Long)\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé depuis : models/k9vxs8ed/mon_agent_trading.zip\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 39\u001B[39m\n\u001B[32m     35\u001B[39m     exit()\n\u001B[32m     38\u001B[39m \u001B[38;5;66;03m# --- 3. Exécution du Backtest ---\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m obs, info = env_test.reset()\n\u001B[32m     40\u001B[39m _states = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     41\u001B[39m done = \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
