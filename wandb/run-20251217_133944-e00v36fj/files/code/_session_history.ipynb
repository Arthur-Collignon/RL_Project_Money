{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8c52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import gym_trading_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe688295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       open    high     low   close       volume  \\\n",
      "date_open                                                          \n",
      "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
      "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
      "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
      "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
      "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
      "\n",
      "                             date_close  \n",
      "date_open                                \n",
      "2020-08-18 07:00:00 2020-08-18 08:00:00  \n",
      "2020-08-18 08:00:00 2020-08-18 09:00:00  \n",
      "2020-08-18 09:00:00 2020-08-18 10:00:00  \n",
      "2020-08-18 10:00:00 2020-08-18 11:00:00  \n",
      "2020-08-18 11:00:00 2020-08-18 12:00:00  "
     ]
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502363a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       open    high     low   close       volume  \\\n",
      "date_open                                                          \n",
      "2020-08-18 07:00:00  430.00  435.00  410.00  430.30   487.154463   \n",
      "2020-08-18 08:00:00  430.27  431.79  430.27  430.80   454.176153   \n",
      "2020-08-18 09:00:00  430.86  431.13  428.71  429.35  1183.710884   \n",
      "2020-08-18 10:00:00  429.75  432.69  428.59  431.90  1686.183227   \n",
      "2020-08-18 11:00:00  432.09  432.89  426.99  427.45  1980.692724   \n",
      "\n",
      "                             date_close  feature_close  \n",
      "date_open                                               \n",
      "2020-08-18 07:00:00 2020-08-18 08:00:00      -1.891634  \n",
      "2020-08-18 08:00:00 2020-08-18 09:00:00      -1.891128  \n",
      "2020-08-18 09:00:00 2020-08-18 10:00:00      -1.892594  \n",
      "2020-08-18 10:00:00 2020-08-18 11:00:00      -1.890016  \n",
      "2020-08-18 11:00:00 2020-08-18 12:00:00      -1.894514  "
     ]
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df['feature_close'] = (df['close'] - df['close'].mean()) / df['close'].std()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess(pd.read_pickle('./data/binance-ETHUSD-1h.pkl'))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f03d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "# On veut une position de 88% ETH / 12% USD\n",
    "obs, reward, terminated, truncated, info = env.step(0.88)\n",
    "print(obs)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae0a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    position_range=(0, 1),  # ICI : (borne min, borne max)\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad50ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_trading_env.wrapper import DiscreteActionsWrapper\n",
    "\n",
    "# Vous pouvez aussi appeler le wrapper `env` pour faire plus simple\n",
    "# Ici, je fais explicitement la distinction entre `wrapper` et `env`\n",
    "wrapper = DiscreteActionsWrapper(env, positions=[-1, 0, 0.25, 0.5, 0.75, 1, 2])\n",
    "obs, _ = wrapper.reset()\n",
    "# On veut une position de 25% ETH / 75% USD ; cela correspond à la position\n",
    "# d'index 2 dans la liste ci-dessus\n",
    "obs, reward, terminated, truncated, info = wrapper.step(2)\n",
    "print(obs)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fad2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(history):\n",
    "    return history['portfolio_valuation', -1]\n",
    "\n",
    "env = gym.make(\n",
    "    \"MultiDatasetTradingEnv\",\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess,\n",
    "    portfolio_initial_value=1_000,\n",
    "    trading_fees=0.1/100,\n",
    "    borrow_interest_rate=0.02/100/24,\n",
    "    # On spécifie la fonction de récompense\n",
    "    reward_function=reward_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a879c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_episodes = 2\n",
    "for episode in range(1, nb_episodes + 1):\n",
    "    obs, _ = env.reset()\n",
    "    print(f'Episode n˚{episode} -- Jeu de donnée {env.name}')\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    if terminated:\n",
    "        print('Argent perdu')\n",
    "    elif truncated:\n",
    "        print('Épisode terminé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c21e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_portfolio_valuation(history):\n",
    "    return round(history['portfolio_valuation', -1], 2)\n",
    "\n",
    "env.add_metric('Portfolio Valuation', metric_portfolio_valuation)\n",
    "\n",
    "done = False\n",
    "obs, _ = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd76e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_valuation = env.historical_info['portfolio_valuation', -1]\n",
    "# Si on avait WandB :\n",
    "# run.summary['portfolio_valuation'] = portfolio_valuation\n",
    "# On simule ça par un simple print...\n",
    "print(portfolio_valuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2dc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = env.get_metrics()\n",
    "print(metrics)\n",
    "portfolio_valuation = metrics['Portfolio Valuation']\n",
    "print(portfolio_valuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2189dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import gym_trading_env\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from stable_baselines3.common.utils import get_latest_run_id\n",
    "\n",
    "\n",
    "## ----------------------------------------------------------------------\n",
    "## A. FONCTIONS DE PRÉTRAITEMENT ET DE RÉCOMPENSE\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "def preprocess_v2(df):\n",
    "    df = df.sort_index().dropna().drop_duplicates()\n",
    "    # Log Returns\n",
    "    df[\"feature_log_returns\"] = np.log(df[\"close\"]).diff()\n",
    "    # Indicateurs de Volatilité (ATR simplifié)\n",
    "    df['tr1'] = df['high'] - df['low']\n",
    "    df['tr2'] = np.abs(df['high'] - df['close'].shift(1))\n",
    "    df['tr3'] = np.abs(df['low'] - df['close'].shift(1))\n",
    "    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)\n",
    "    df['feature_atr'] = df['tr'].rolling(window=14).mean() / df[\"close\"]\n",
    "    # Indicateurs de Tendance (MACD)\n",
    "    ema_fast = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_slow = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['feature_macd'] = ema_fast - ema_slow\n",
    "    df['feature_macd_signal'] = df['feature_macd'].ewm(span=9, adjust=False).mean()\n",
    "    # Indicateurs de Momentum (RSI)\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    # Normalisation finale\n",
    "    df['feature_rsi'] = 100 - (100 / (1 + rs)) / 100\n",
    "    df = df.dropna()\n",
    "    cols_to_normalize = ['feature_log_returns', 'feature_macd', 'feature_macd_signal', 'feature_atr']\n",
    "    for col in cols_to_normalize:\n",
    "        if df[col].std() > 0:\n",
    "            df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "        else:\n",
    "             df[col] = 0.0\n",
    "    return df\n",
    "\n",
    "def reward_function_v2(history):\n",
    "    # Log-Return différentiel\n",
    "    prev_val = history['portfolio_valuation', -2]\n",
    "    curr_val = history['portfolio_valuation', -1]\n",
    "    if prev_val == 0: return 0\n",
    "    reward = np.log(curr_val / prev_val)\n",
    "    return reward\n",
    "\n",
    "## ----------------------------------------------------------------------\n",
    "## B. CUSTOM CALLBACK WANDB (Métriques financières)\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "class CustomTradingCallback(BaseCallback):\n",
    "    def __init__(self, verbose: int = 0):\n",
    "        super().__init__(verbose)\n",
    "        self.episode_num = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.locals['dones'][0]:\n",
    "            self.episode_num += 1\n",
    "            raw_env = self.training_env.envs[0].unwrapped\n",
    "            metrics = raw_env.get_metrics()\n",
    "\n",
    "            # Récupération des retours pour le calcul de performance\n",
    "            market_return_str = metrics.get('Market Return', '0.00%').strip()\n",
    "            market_return = float(market_return_str.strip('%')) / 100\n",
    "            portfolio_return_str = metrics.get('Portfolio Return', '0.00%').strip()\n",
    "            portfolio_return = float(portfolio_return_str.strip('%')) / 100\n",
    "\n",
    "            if self.logger is not None:\n",
    "                self.logger.record(\"episode/final_portfolio_valuation\", metrics.get('Portfolio Valuation'))\n",
    "                self.logger.record(\"episode/return_vs_market_pct\", (portfolio_return - market_return) * 100)\n",
    "                self.logger.record(\"episode/total_portfolio_return_pct\", portfolio_return * 100)\n",
    "                self.logger.record(\"episode/market_return_pct\", market_return * 100)\n",
    "                self.logger.record(\"episode/steps\", raw_env.step) # CORRECTION : raw_env.step\n",
    "\n",
    "                self.logger.dump(step=self.num_timesteps)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52b67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. HYPERPARAMÈTRES ET CONFIGURATION GLOBALE ---\n",
    "config = {\n",
    "    \"policy_type\": \"MlpLstmPolicy\",\n",
    "    \"total_timesteps\": 100_000,\n",
    "    \"env_id\": \"MultiDatasetTradingEnv\",\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 128,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"portfolio_initial_value\": 1_000,\n",
    "    \"trading_fees\": 0.1/100,\n",
    "    \"borrow_interest_rate\": 0.02/100/24,\n",
    "    \"positions_range\": (-1, 1),\n",
    "    \"model_name\": \"mon_agent_trading\" # Nom de base pour la sauvegarde\n",
    "}\n",
    "\n",
    "# --- 2. INITIALISATION DE WANDB ET RÉCUPÉRATION DU CHEMIN DE SAUVEGARDE ---\n",
    "run = wandb.init(\n",
    "    project=\"RL-Trading-Project\",\n",
    "    entity=\"arthur-collignon-cpe-lyon\",\n",
    "    config=config,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym=True,\n",
    "    save_code=True,\n",
    ")\n",
    "\n",
    "# Chemin où SB3 sauvegardera le modèle (dans le dossier WandB)\n",
    "# Nous stockons ce chemin dans une variable globale pour le backtesting.\n",
    "MODEL_SAVE_PATH = f\"models/{run.id}/{config['model_name']}.zip\"\n",
    "WANDB_RUN_ID = run.id # Sauvegarde de l'ID du run actuel\n",
    "\n",
    "# --- 3. CRÉATION DE L'ENVIRONNEMENT ET DU MODÈLE ---\n",
    "env = gym.make(\n",
    "    config[\"env_id\"],\n",
    "    dataset_dir=\"data/*.pkl\",\n",
    "    preprocess=preprocess_v2,\n",
    "    reward_function=reward_function_v2,\n",
    "    position_range=config[\"positions_range\"],\n",
    "    portfolio_initial_value=config[\"portfolio_initial_value\"],\n",
    "    trading_fees=config[\"trading_fees\"],\n",
    "    borrow_interest_rate=config[\"borrow_interest_rate\"],\n",
    ")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = RecurrentPPO(\n",
    "    config[\"policy_type\"], env, verbose=0, **{k: config[k] for k in ['learning_rate', 'n_steps', 'batch_size', 'ent_coef']}\n",
    ")\n",
    "\n",
    "# --- 4. DÉFINITION DE LA LISTE DE CALLBACKS ---\n",
    "callback = CallbackList([\n",
    "    WandbCallback(\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=0,\n",
    "        model_save_freq=10000,\n",
    "        # Nom de fichier personnalisé (pour le rendre facilement chargeable)\n",
    "        # Note: ceci nécessite un hack pour s'assurer que le nom est constant\n",
    "        # La sauvegarde finale sera gérée manuellement.\n",
    "    ),\n",
    "    CustomTradingCallback(verbose=0),\n",
    "])\n",
    "\n",
    "# --- 5. ENTRAÎNEMENT ET SAUVEGARDE FINALE ---\n",
    "try:\n",
    "    print(\"Début de l'entraînement avec WandB...\")\n",
    "    model.learn(\n",
    "        total_timesteps=config[\"total_timesteps\"],\n",
    "        callback=callback,\n",
    "    )\n",
    "    # Sauvegarde finale manuelle dans le chemin exact\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    print(f\"Modèle sauvegardé dans : {MODEL_SAVE_PATH}\")\n",
    "finally:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
